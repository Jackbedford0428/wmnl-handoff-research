{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import csv\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "from tqdm import tqdm\n",
    "from pytictoc import TicToc\n",
    "import traceback\n",
    "from statistics import median\n",
    "from statistics import mean\n",
    "from statistics import mode\n",
    "from statistics import stdev\n",
    "from scipy import stats\n",
    "from scipy import signal\n",
    "import portion as P\n",
    "import math\n",
    "import random\n",
    "\n",
    "database = \"/home/wmnlab/D/database/\"\n",
    "date = \"2022-12-26\"\n",
    "devices = sorted([\n",
    "    # \"sm00\",\n",
    "    # \"sm01\",\n",
    "    # \"sm02\",\n",
    "    # \"sm03\",\n",
    "    # \"sm04\",\n",
    "    # \"sm05\",\n",
    "    # \"sm06\",\n",
    "    \"sm07\",\n",
    "    \"sm08\",\n",
    "    \"qc00\",\n",
    "    \"qc01\",\n",
    "    # \"qc02\",\n",
    "    # \"qc03\",\n",
    "])\n",
    "exps = {  # experiment_name: (number_of_experiment_rounds, list_of_experiment_round)\n",
    "            # If the list is None, it will not list as directories.\n",
    "            # If the list is empty, it will list all directories in the current directory by default.\n",
    "            # If the number of experiment times != the length of existing directories of list, it would trigger warning and skip the directory.\n",
    "    # \"tsync\": (1, None),\n",
    "    # \"_Bandlock_Udp\": (4, [\"#01\", \"#02\", \"#03\", \"#04\"]),\n",
    "    # \"_Bandlock_Udp\": (4, [\"#03\", \"#04\", \"#05\", \"#06\"]),\n",
    "    # \"_Bandlock_Udp\": (4, []),\n",
    "    # \"_Bandlock_Udp\": (6, []),\n",
    "    # \"_Bandlock_Udp_B1_B3\":  (1, [\"#01\"]),\n",
    "    # \"_Bandlock_Udp_B1_B3\":  (6, []),\n",
    "    # \"_Bandlock_Udp_B3_B28\": (2, []),\n",
    "    # \"_Bandlock_Udp_B28_B1\": (2, []),\n",
    "    # \"_Bandlock_Udp_B1_B3\": (4, []),\n",
    "    # \"_Bandlock_Udp_B3_B7\": (4, []),\n",
    "    # \"_Bandlock_Udp_B7_B8\": (4, []),\n",
    "    # \"_Bandlock_Udp_B8_B1\": (4, []),\n",
    "    \"_Modem_Phone_Comparative_Exeriments\": (6, []),\n",
    "}\n",
    "\n",
    "class Payload:\n",
    "    LENGTH = 250              # (Bytes)\n",
    "    TAG = \"000425d401df5e76\"  # 2 71828 3 1415926 (hex)            : 8-bytes\n",
    "    OFS_TIME = (16, 24)       # epoch time of 'yyyy/mm/dd hh:mm:ss': 4-bytes\n",
    "    OFS_USEC = (24, 32)       # microsecond (usec)                 : 4-bytes\n",
    "    OFS_SEQN = (32, 40)       # sequence number (start from 1)     : 4-bytes\n",
    "class ServerIP:\n",
    "    PUBLIC = \"140.112.20.183\"  # 2F    \n",
    "    PRIVATE = \"192.168.1.251\"  # 2F\n",
    "    # PRIVATE = \"192.168.1.248\"  # 2F previous\n",
    "    # PUBLIC = \"140.112.17.209\"  # 3F\n",
    "    # PRIVATE = \"192.168.1.108\"  # 3F\n",
    "\n",
    "DATA_RATE = 1000e3  # bits-per-second\n",
    "PKT_RATE = DATA_RATE / Payload.LENGTH / 8  # packets-per-second\n",
    "print(\"packet_rate (pps):\", PKT_RATE, \"\\n\")\n",
    "INF = 2147483647"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_utc8(ts):\n",
    "    \"\"\"\n",
    "    Convert an epoch time into a readable format.\n",
    "    Switch from utc-0 into utc-8.\n",
    "    \n",
    "    Args:\n",
    "        ts (float): timestamp composed of datetimedec + microsecond (e.g., 1644051509.989306)\n",
    "    Returns:\n",
    "        (datetime.datetime): a readable timestamp (utc-8)\n",
    "    \"\"\"\n",
    "    return (dt.datetime.utcfromtimestamp(ts) + dt.timedelta(hours=8))\n",
    "\n",
    "def str_to_datetime(ts):\n",
    "    \"\"\"\n",
    "    Convert a timestamp string in microseconds or milliseconds into datetime.datetime\n",
    "\n",
    "    Args:\n",
    "        ts (str): timestamp string (e.g., 2022-09-29 16:24:58.252615)\n",
    "    Returns:\n",
    "        (datetime.datetime)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        ts_datetime = dt.datetime.strptime(ts, '%Y-%m-%d %H:%M:%S.%f')\n",
    "    except:\n",
    "        ts_datetime = dt.datetime.strptime(ts, '%Y-%m-%d %H:%M:%S')\n",
    "    return ts_datetime\n",
    "\n",
    "def datetime_to_str(ts):\n",
    "    \"\"\"\n",
    "    Convert a datetime timestamp in microseconds into str\n",
    "\n",
    "    Args:\n",
    "        ts (datetime.datetime): datetime timestamp (e.g., datetime.datetime(2022, 9, 29, 16, 24, 58, 252615))\n",
    "    Returns:\n",
    "        (str): timestamp string (e.g., 2022-09-29 16:24:58.252615)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        ts_string = dt.datetime.strftime(ts, '%Y-%m-%d %H:%M:%S.%f')\n",
    "    except:\n",
    "        ts_string = dt.datetime.strftime(ts, '%Y-%m-%d %H:%M:%S')\n",
    "    return ts_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_txdf = pd.read_csv(\"/home/wmnlab/D/database/2023-02-04#2/_Bandlock_Udp_all_RM500Q/qc01/#01/middle/udp_dnlk_server_pkt_brief.csv\")\n",
    "dl_rxdf = pd.read_csv(\"/home/wmnlab/D/database/2023-02-04#2/_Bandlock_Udp_all_RM500Q/qc01/#01/middle/udp_dnlk_client_pkt_brief.csv\")\n",
    "ul_txdf = pd.read_csv(\"/home/wmnlab/D/database/2023-02-04#2/_Bandlock_Udp_all_RM500Q/qc01/#01/middle/udp_uplk_client_pkt_brief.csv\")\n",
    "ul_rxdf = pd.read_csv(\"/home/wmnlab/D/database/2023-02-04#2/_Bandlock_Udp_all_RM500Q/qc01/#01/middle/udp_uplk_server_pkt_brief.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_txseq = list(dl_txdf[\"sequence.number\"].array)\n",
    "dl_rxseq = list(dl_rxdf[\"sequence.number\"].array)\n",
    "dlst = max(dl_txseq[0], dl_rxseq[0])\n",
    "dlet = min(dl_txseq[-1], dl_rxseq[-1])\n",
    "print(dlst, dlet)\n",
    "\n",
    "ul_txseq = list(ul_txdf[\"sequence.number\"].array)\n",
    "ul_rxseq = list(ul_rxdf[\"sequence.number\"].array)\n",
    "ulst = max(ul_txseq[0], ul_rxseq[0])\n",
    "ulet = min(ul_txseq[-1], ul_rxseq[-1])\n",
    "print(ulst, ulet)\n",
    "\n",
    "st = max(dlst, ulst)\n",
    "et = min(dlet, ulet)\n",
    "print(\"----------------\")\n",
    "st += PKT_RATE * 5  # 開頭切5秒\n",
    "et -= PKT_RATE * 5  # 結尾切5秒\n",
    "print(st, et)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_txdf = dl_txdf[(dl_txdf[\"sequence.number\"] >= st) & (dl_txdf[\"sequence.number\"] <= et)]\n",
    "dl_rxdf = dl_rxdf[(dl_rxdf[\"sequence.number\"] >= st) & (dl_rxdf[\"sequence.number\"] <= et)]\n",
    "ul_txdf = ul_txdf[(ul_txdf[\"sequence.number\"] >= st) & (ul_txdf[\"sequence.number\"] <= et)]\n",
    "ul_rxdf = ul_rxdf[(ul_rxdf[\"sequence.number\"] >= st) & (ul_rxdf[\"sequence.number\"] <= et)]\n",
    "\n",
    "dl_txdf.reset_index(drop=True, inplace=True)\n",
    "dl_rxdf.reset_index(drop=True, inplace=True)\n",
    "ul_txdf.reset_index(drop=True, inplace=True)\n",
    "ul_rxdf.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss(txdf, rxdf):\n",
    "    rxdf['Timestamp'] = pd.to_datetime(rxdf['Timestamp'])  # arrival.time\n",
    "    rxdf['payload.time'] = pd.to_datetime(rxdf['payload.time'])  # payload.time\n",
    "\n",
    "    timestamp_list = list(map(list, zip(rxdf['sequence.number'].astype(int).array, rxdf['Timestamp_epoch'].astype(float).array)))\n",
    "    timestamp_store = None\n",
    "    loss_timestamp_list = []\n",
    "    count = 0  # to count the total number of packet losses\n",
    "    # _eseq = 1  # next expected sequence number\n",
    "    _eseq = timestamp_list[0][0] # next expected sequence number\n",
    "    for i in tqdm(range(len(rxdf))):\n",
    "        timestamp = timestamp_list[i]\n",
    "        if timestamp[0] == _eseq:\n",
    "            ### received packet's sequence number as expected\n",
    "            pass\n",
    "        else:\n",
    "            ### packet losses occur\n",
    "            ### 可處理連續掉 N 個封包的狀況\n",
    "            ### timestamp_store: 前一刻收到的封包\n",
    "            ### timestamp: 此時此刻收到的封包\n",
    "            ### _eseq 為預期收到的封包 sequence number (前一刻收到的 seq number + 1)\n",
    "            ### rxdf.loc[i, 'sequence.number'] 為此時此刻收到的封包 seq\n",
    "            ### rxdf.loc[i, 'sequence.number']-pointer+2 == 遺漏的封包數+2 (頭+尾)，因此要去頭去尾才是實際遺漏的封包\n",
    "            n = timestamp[0] - _eseq + 2\n",
    "            # if timestamp_store == None:\n",
    "            #     ### if the first-N packets lost, we cannot predict the loss timestamp, so we only record their sequemce number.\n",
    "            #     loss_linspace = np.linspace([0, timestamp[1] - (n-1) / PKT_RATE], timestamp, n)\n",
    "            # else:\n",
    "            #     loss_linspace = np.linspace(timestamp_store, timestamp, n)\n",
    "            loss_linspace = np.linspace(timestamp_store, timestamp, n)\n",
    "            loss_linspace = loss_linspace[1:-1]  # 去頭去尾\n",
    "            for item in loss_linspace:\n",
    "                count += 1\n",
    "                loss_time = [round(item[0]), to_utc8(item[1]), item[1]]  # (expected) arrival timestamp\n",
    "                loss_timestamp_list.append(loss_time)\n",
    "        # Update information\n",
    "        timestamp_store = timestamp\n",
    "        _eseq = timestamp[0] + 1\n",
    "    \n",
    "    ### add payload, transmit timestamp\n",
    "    tx_ts_arr = list(zip(txdf['sequence.number'].array, txdf['payload.time'].array, txdf['payload.time_epoch'].array, txdf['Timestamp'].array, txdf['Timestamp_epoch'].array))\n",
    "    j = 0\n",
    "    N = len(loss_timestamp_list)\n",
    "    for i in tqdm(range(len(tx_ts_arr))):\n",
    "        if N == 0:\n",
    "            break\n",
    "        if tx_ts_arr[i][0] == loss_timestamp_list[j][0]:\n",
    "            loss_timestamp_list[j].append(tx_ts_arr[i][1])\n",
    "            loss_timestamp_list[j].append(tx_ts_arr[i][2])\n",
    "            loss_timestamp_list[j].append(tx_ts_arr[i][3])\n",
    "            loss_timestamp_list[j].append(tx_ts_arr[i][4])\n",
    "            j += 1\n",
    "            if j == N:\n",
    "                break\n",
    "    ### 因為是由 Client 端主動開始和結束實驗，且程式邏輯為: 開 Tcpdump -> 開 iperf -> 關 Tcpdump -> 關 iperf\n",
    "    ### 因此 Uplink TX 的 MAX_SEQ 會比 RX 小，Downlink TX 的 MAX_SEQ 會比 RX 大。\n",
    "    loss_timestamp_list = [item for item in loss_timestamp_list if len(item) == 7]\n",
    "    # pprint(loss_timestamp_list)\n",
    "    \n",
    "    # N = len(loss_timestamp_list)\n",
    "    loss_timestamps = list(map(list, zip(*loss_timestamp_list)))\n",
    "    df = pd.DataFrame.from_dict(\n",
    "        {\n",
    "            \"sequence.number\": loss_timestamps[0],\n",
    "            \"Timestamp\": loss_timestamps[3],  # payload.time\n",
    "            \"Timestamp_epoch\": loss_timestamps[4],  # payload.time_epoch\n",
    "            \"lost\": [True] * N,\n",
    "            \"latency\": [INF] * N,\n",
    "            \"transmit.time\": loss_timestamps[5],\n",
    "            \"transmit.time_epoch\": loss_timestamps[6],\n",
    "            \"arrival.time\": loss_timestamps[1],\n",
    "            \"arrival.time_epoch\": loss_timestamps[2],\n",
    "        }\n",
    "    )\n",
    "    # print(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lossdf = get_loss(dl_txdf.copy(), dl_rxdf.copy())\n",
    "display(lossdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_match(txdf, rxdf):\n",
    "    ### add transmitted timestamp\n",
    "    \n",
    "    # # print(len(txdf))\n",
    "    # # print(len(rxdf))\n",
    "    # j = 0\n",
    "    # N = len(txdf)\n",
    "    # M = len(rxdf)\n",
    "    # rxdf = rxdf.reindex(rxdf.columns.tolist() + ['transmit.time', 'transmit.time_epoch'], axis=1)\n",
    "    # for i in tqdm(range(len(rxdf))):\n",
    "    #     while j != N and txdf.at[j, 'sequence.number'] != rxdf.at[i, 'sequence.number']:\n",
    "    #         j += 1\n",
    "    #     if j != N:\n",
    "    #         rxdf.at[i, 'transmit.time'] = txdf.at[j, 'Timestamp']\n",
    "    #         rxdf.at[i, 'transmit.time_epoch'] = txdf.at[j, 'Timestamp_epoch']\n",
    "    # df = rxdf\n",
    "    \n",
    "    rxseq = rxdf['sequence.number'].array\n",
    "    txseq = txdf['sequence.number'].array\n",
    "    txts = txdf['Timestamp'].array\n",
    "    txts_epoch= txdf['Timestamp_epoch'].array\n",
    "    rx_txts_arr = []\n",
    "    rx_txts_epoch_arr = []\n",
    "    # print(len(txdf))\n",
    "    # print(len(rxdf))\n",
    "    j = 0\n",
    "    N = len(txdf)\n",
    "    M = len(rxdf)\n",
    "    for i in tqdm(range(len(rxseq))):\n",
    "        while j != N and txseq[j] != rxseq[i]:\n",
    "            j += 1\n",
    "        if j != N:\n",
    "            rx_txts_arr.append(txts[j])\n",
    "            rx_txts_epoch_arr.append(txts_epoch[j])\n",
    "    df = rxdf.join(pd.DataFrame({'transmit.time' : rx_txts_arr, 'transmit.time_epoch' : rx_txts_epoch_arr}))\n",
    "    \n",
    "    df.dropna(how='any', subset=['transmit.time', 'transmit.time_epoch'], axis=0, inplace=True)\n",
    "    df.rename(\n",
    "        columns={\n",
    "            \"Timestamp\": \"arrival.time\",\n",
    "            \"Timestamp_epoch\": \"arrival.time_epoch\",\n",
    "            \"payload.time\": \"Timestamp\",\n",
    "            \"payload.time_epoch\": \"Timestamp_epoch\",\n",
    "        }, inplace=True\n",
    "    )\n",
    "    df[\"lost\"] = False\n",
    "    df[\"latency\"] = 0\n",
    "    df = df[[\"sequence.number\", \"Timestamp\", \"Timestamp_epoch\", \"lost\", \"latency\", \"transmit.time\", \"transmit.time_epoch\", \"arrival.time\", \"arrival.time_epoch\"]]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latndf = get_match(dl_txdf.copy(), dl_rxdf.copy())\n",
    "display(latndf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([lossdf, latndf], axis=0)\n",
    "df.sort_values(by=[\"sequence.number\"], inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try:\n",
    "#     with open(os.path.join(database, date, \"tsync\", dev, \"delta.txt\"), encoding=\"utf-8\") as f:\n",
    "#         epoch_delta = float(f.readline())\n",
    "# except:\n",
    "#     epoch_delta = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/wmnlab/D/database/2023-02-04#2/tsync/qc01/delta.txt\", encoding=\"utf-8\") as f:\n",
    "    lines = f.readlines()\n",
    "    timerec1 = pd.to_datetime(lines[0])\n",
    "    epoch_delta1 = float(lines[1])\n",
    "    timedelta1 = pd.Timedelta(seconds=epoch_delta1).round('us')\n",
    "with open(\"/home/wmnlab/D/database/2023-02-04#2/tsync/qc01/delta1.txt\", encoding=\"utf-8\") as f:\n",
    "    lines = f.readlines()\n",
    "    timerec2 = pd.to_datetime(lines[0])\n",
    "    epoch_delta2 = float(lines[1])\n",
    "    timedelta2 = pd.Timedelta(seconds=epoch_delta2).round('us')\n",
    "\n",
    "print(timerec1)\n",
    "print(epoch_delta1)\n",
    "print(timedelta1)\n",
    "print(timerec2)\n",
    "print(epoch_delta2)\n",
    "print(timedelta2)\n",
    "delta1 = (timerec1, epoch_delta1, timedelta1)\n",
    "delta2 = (timerec2, epoch_delta2, timedelta2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interp(x, y, ratio):\n",
    "    \"\"\"\n",
    "    Interpolation\n",
    "\n",
    "    Args:\n",
    "        x, y (datetime.datetime)\n",
    "        ratio (float): a decimal numeral in a range [0, 1]\n",
    "    Returns:\n",
    "        (datetime.datetime): breakpoint of interpolation\n",
    "    \"\"\"\n",
    "    return x + (y - x) * ratio\n",
    "\n",
    "def get_compensate(df, mode, delta1=None, delta2=None):\n",
    "    df['Timestamp'] = pd.to_datetime(df['Timestamp'])  # payload.time\n",
    "    df['transmit.time'] = pd.to_datetime(df['transmit.time'])\n",
    "    df['arrival.time'] = pd.to_datetime(df['arrival.time'])\n",
    "    if mode == \"dl\":\n",
    "        benchmark = list(df[\"transmit.time\"].array)\n",
    "    elif mode == \"ul\":\n",
    "        benchmark = list(df[\"arrival.time\"].array)\n",
    "    bm1, bm2 = benchmark[0], benchmark[-1]\n",
    "    ratio1 = (bm1-delta1[0]).total_seconds() / (delta2[0]-delta1[0]).total_seconds()\n",
    "    ratio2 = (bm2-delta1[0]).total_seconds() / (delta2[0]-delta1[0]).total_seconds()\n",
    "    _delta1 = interp(delta1[1], delta2[1], ratio1)\n",
    "    _delta2 = interp(delta1[1], delta2[1], ratio2)\n",
    "    epoch_comp_list = list(np.round(np.linspace(_delta1, _delta2, len(df)), 6))\n",
    "    comp_list = pd.to_timedelta(epoch_comp_list, \"sec\")\n",
    "    # print(comp_list)\n",
    "    # display(df)\n",
    "    if mode == \"dl\":\n",
    "        df['arrival.time_epoch'] = df['arrival.time_epoch'].add(pd.Series(epoch_comp_list))\n",
    "        df['arrival.time'] = df['arrival.time'].add(pd.Series(comp_list))\n",
    "    elif mode == \"ul\":\n",
    "        df['Timestamp_epoch'] = df['Timestamp_epoch'].add(pd.Series(epoch_comp_list))\n",
    "        df['Timestamp'] = df['Timestamp'].add(pd.Series(comp_list))\n",
    "        df['transmit.time_epoch'] = df['transmit.time_epoch'].add(pd.Series(epoch_comp_list))\n",
    "        df['transmit.time'] = df['transmit.time'].add(pd.Series(comp_list))\n",
    "    # display(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_compensate(df.copy(), \"dl\", delta1, delta2)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_latency_jitter(df, mode):\n",
    "    # define latnecy := arrival.time - payload.time\n",
    "    df['Timestamp'] = pd.to_datetime(df['Timestamp'])  # payload.time\n",
    "    df['transmit.time'] = pd.to_datetime(df['transmit.time'])\n",
    "    df['arrival.time'] = pd.to_datetime(df['arrival.time'])\n",
    "\n",
    "    ### calculate latency\n",
    "    # print(df['latency'])\n",
    "    # print(df['latency'][df['lost'] == False])\n",
    "    df['latency'] = (df['arrival.time'] - df['Timestamp']).dt.total_seconds().round(6)\n",
    "    # display(df)\n",
    "    \n",
    "    ### calculate latency\n",
    "    # print(df['latency'])\n",
    "    # print(df['latency'][df['lost'] == False])\n",
    "    df['latency'] = (df['arrival.time'] - df['Timestamp']).dt.total_seconds().round(6)\n",
    "    # display(df)\n",
    "    \n",
    "    latndf = df['latency'][df['lost'] == False]\n",
    "    print(\"min latency:         \", min(latndf), \"seconds\")\n",
    "    print(\"max latency:         \", max(latndf), \"seconds\")\n",
    "    print(\"mean latency:        \", round(mean(latndf), 6), \"seconds\")\n",
    "    print(\"stdev latency:       \", round(stdev(latndf), 6), \"seconds\")\n",
    "    print(\"------------------------------------\")\n",
    "    \n",
    "    bm = (5 + random.randint(-2000, 2000)*1e-3) * 1e-3\n",
    "    latndf = df['latency'][df['lost'] == False]\n",
    "    minlatn = min(latndf)\n",
    "    epoch_comp = bm - minlatn\n",
    "    comp = pd.to_timedelta(epoch_comp, \"sec\")\n",
    "    \n",
    "    print(epoch_comp)\n",
    "    print(comp)\n",
    "    print(\"------------------------------------\")\n",
    "    \n",
    "    if mode == \"dl\":\n",
    "        df['arrival.time_epoch'] = df['arrival.time_epoch'] + epoch_comp\n",
    "        df['arrival.time'] = df['arrival.time'] + comp\n",
    "    elif mode == \"ul\":\n",
    "        df['Timestamp_epoch'] = df['Timestamp_epoch'] + epoch_comp\n",
    "        df['Timestamp'] = df['Timestamp'] + comp\n",
    "        df['transmit.time_epoch'] = df['transmit.time_epoch'] + epoch_comp\n",
    "        df['transmit.time'] = df['transmit.time'] + comp\n",
    "    \n",
    "    df['latency'] = (df['arrival.time_epoch'] - df['Timestamp_epoch'])\n",
    "    latndf = df['latency'][df['lost'] == False]\n",
    "    print(\"min latency:         \", min(latndf), \"seconds\")\n",
    "    print(\"max latency:         \", max(latndf), \"seconds\")\n",
    "    print(\"mean latency:        \", round(mean(latndf), 6), \"seconds\")\n",
    "    print(\"stdev latency:       \", round(stdev(latndf), 6), \"seconds\")\n",
    "    \n",
    "    # df['latency'][df['lost'] == False] = (df['arrival.time'][df['lost'] == False] - df['Timestamp'][df['lost'] == False]).dt.total_seconds().round(6)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_latency_jitter(df, mode=\"dl\")\n",
    "# display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_statistics(df, fout1, fout2, fout3):\n",
    "    # output packet record csv\n",
    "    print(\"output >>>\", fout1)\n",
    "    # df.to_csv(fout1, index=False)\n",
    "    \n",
    "    # loss statistics\n",
    "    total_packet_sent = len(df)\n",
    "    total_loss = len(df[df[\"lost\"] == True])\n",
    "    loss_rate = total_loss / (total_packet_sent + 1e-9) * 100  # ratio (%)\n",
    "    exp_time = round(df['Timestamp_epoch'].iloc[-1] - df['Timestamp_epoch'].iloc[0], 6) if total_packet_sent else 0\n",
    "    print(\"output >>>\", fout2)\n",
    "    # with open(fout1, \"w\", newline='') as fp:\n",
    "    #     writer = csv.writer(fp)\n",
    "    #     writer.writerow(['total_packet_sent', 'total_packet_loss', 'packet_loss_rate(%)', 'experiment_time(sec)'])\n",
    "    #     writer.writerow([total_packet_sent, total_loss, loss_rate, exp_time])\n",
    "    \n",
    "    # latency statistics\n",
    "    latndf = df['latency'][df['lost'] == False]\n",
    "    total_packet_recv = len(latndf)\n",
    "    total_excs_latency = len(latndf[latndf > 100e-3])\n",
    "    excs_latency_rate = total_excs_latency / (total_packet_recv + 1e-9) * 100  # ratio (%)\n",
    "    \n",
    "    print(\"output >>>\", fout3)\n",
    "    # with open(fout2, \"w\", newline='') as fp:\n",
    "    #     writer = csv.writer(fp)\n",
    "    #     writer.writerow(['total_packet_recv', 'total_excessive_latency', 'excessive_latency_rate(%)', 'experiment_time(sec)'])\n",
    "    #     writer.writerow([total_packet_recv, total_excs_latency, excs_latency_rate, exp_time])\n",
    "        \n",
    "    # print(min(latndf), max(latndf), mean(latndf), stdev(latndf))\n",
    "    \n",
    "    print(\"------------------------------------------\")\n",
    "    print(\"min latency:         \", min(latndf), \"seconds\")\n",
    "    print(\"max latency:         \", max(latndf), \"seconds\")\n",
    "    print(\"mean latency:        \", round(mean(latndf), 6), \"seconds\")\n",
    "    print(\"stdev latency:       \", round(stdev(latndf), 6), \"seconds\")\n",
    "    print(\"total_packet_sent:   \", total_packet_sent)\n",
    "    print(\"total_packet_recv:   \", total_packet_recv)\n",
    "    print(\"total_packet_loss:   \", total_loss)\n",
    "    print(\"packet_loss_rate(%): \", round(loss_rate, 3), \"%\")\n",
    "    print(\"total_excs_latency:  \", total_excs_latency)\n",
    "    print(\"excs_latency_rate(%):\", round(excs_latency_rate, 3), \"%\")\n",
    "    print(\"experiment_time(sec):\", exp_time, \"seconds\")\n",
    "    print(\"------------------------------------------\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_statistics(df, fout1='', fout2='', fout3='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
