{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import csv\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "from tqdm import tqdm\n",
    "from pytictoc import TicToc\n",
    "import traceback\n",
    "from statistics import median\n",
    "from statistics import mean\n",
    "from statistics import mode\n",
    "from statistics import stdev\n",
    "from scipy import stats\n",
    "from scipy import signal\n",
    "import portion as P\n",
    "import math\n",
    "import random\n",
    "import itertools\n",
    "\n",
    "# ******************************* User Settings *******************************\n",
    "database = \"/home/wmnlab/D/database/\"\n",
    "dates = [\n",
    "        #  \"2023-02-04\",\n",
    "        #  \"2023-02-04#1\",\n",
    "        #  \"2023-02-27\",\n",
    "         \"2023-03-15\"\n",
    "         ]\n",
    "devices = [\n",
    "    # \"sm00\",\n",
    "    # \"sm01\",\n",
    "    # \"sm02\",\n",
    "    # \"sm03\",\n",
    "    # \"sm04\",\n",
    "    # \"sm05\",\n",
    "    # \"sm06\",\n",
    "    # \"sm07\",\n",
    "    # \"sm08\",\n",
    "    \"qc00\",\n",
    "    \"qc01\",\n",
    "    \"qc02\",\n",
    "    \"qc03\",\n",
    "]\n",
    "schemes = [\n",
    "    # \"qc00\",\n",
    "    # \"qc01\",\n",
    "    \"B1\",\n",
    "    \"B3\",\n",
    "    \"B7\",\n",
    "    \"B8\",\n",
    "    # \"All@qc01\",\n",
    "    # \"All@qc02\",\n",
    "    # \"All@qc03\",\n",
    "]\n",
    "exps = {  # experiment_name: (number_of_experiment_rounds, list_of_experiment_round)\n",
    "            # If the list is None, it will not list as directories.\n",
    "            # If the list is empty, it will list all directories in the current directory by default.\n",
    "            # If the number of experiment times != the length of existing directories of list, it would trigger warning and skip the directory.\n",
    "    # \"_Bandswitch\": (1, [\"#01\",]),\n",
    "    \"_Bandlock_Udp_B1_B3_B7_B8_RM500Q\": (6, [\"#01\", \"#02\", \"#03\", \"#04\", \"#05\", \"#06\"]),\n",
    "    # \"_Bandlock_Udp_B3_B7_B8_RM500Q\": (2, [\"#01\", \"#02\"]),\n",
    "    # \"_Bandlock_Udp_all_RM500Q\": (1, [\"#01\",]),\n",
    "    # \"_Bandlock_Udp_all_RM500Q\": (2, [\"#01\", \"#02\"]),\n",
    "}\n",
    "\n",
    "INF = 2147483647\n",
    "LENGTH = 250\n",
    "DATA_RATE = 1000e3  # bits-per-second\n",
    "PKT_RATE = DATA_RATE / LENGTH / 8  # packets-per-second\n",
    "print(\"packet_rate (pps):\", PKT_RATE, \"\\n\")\n",
    "# *****************************************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makedir(dirpath, mode=0):  # mode=1: show message, mode=0: hide message\n",
    "    if os.path.isdir(dirpath):\n",
    "        if mode:\n",
    "            print(\"mkdir: cannot create directory '{}': directory has already existed.\".format(dirpath))\n",
    "        return\n",
    "    ### recursively make directory\n",
    "    _temp = []\n",
    "    while not os.path.isdir(dirpath):\n",
    "        _temp.append(dirpath)\n",
    "        dirpath = os.path.dirname(dirpath)\n",
    "    while _temp:\n",
    "        dirpath = _temp.pop()\n",
    "        print(\"mkdir\", dirpath)\n",
    "        os.mkdir(dirpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for date in dates:\n",
    "    for expr, (times, traces) in exps.items():\n",
    "        for trace in traces:\n",
    "            target_dir = os.path.join(database, date, expr, \"combo\", trace)\n",
    "            makedir(target_dir)\n",
    "            for tag in [\"dnlk\", \"uplk\"]:\n",
    "            # for tag in [\"dnlk\",]:\n",
    "                print(\"------------------------------------------\")\n",
    "                print(date, expr, trace, tag)  \n",
    "                print(\"------------------------------------------\")\n",
    "                t = TicToc()\n",
    "                t.tic()\n",
    "                dfs = []\n",
    "                for i, (dev, scheme) in enumerate(zip(devices, schemes)):\n",
    "                    source_dir = os.path.join(database, date, expr, dev, trace, \"data\")\n",
    "                    dfs.append(pd.read_csv(os.path.join(source_dir, f\"udp_{tag}_loss_latency.csv\")))\n",
    "                ### TODO 1\n",
    "                st, et = [], []\n",
    "                for i, (dev, scheme) in enumerate(zip(devices, schemes)):\n",
    "                    st.append(dfs[i]['sequence.number'].array[0])\n",
    "                    et.append(dfs[i]['sequence.number'].array[-1])\n",
    "                st, et = max(st), min(et)\n",
    "                for i, (dev, scheme) in enumerate(zip(devices, schemes)):\n",
    "                    dfs[i] = dfs[i][(dfs[i]['sequence.number'] >= st) & (dfs[i]['sequence.number'] <= et)]\n",
    "                    dfs[i].reset_index(drop=True, inplace=True)\n",
    "                # df = dfs[0][['sequence.number', 'Timestamp', 'Timestamp_epoch']]\n",
    "                df = dfs[0][['sequence.number', 'Timestamp']]\n",
    "                for i, (dev, scheme) in enumerate(zip(devices, schemes)):\n",
    "                    # dfs[i] = dfs[i][['lost', 'excl', 'latency']]\n",
    "                    dfs[i] = dfs[i][['transmit.time','arrival.time','lost','excl','latency']]\n",
    "                    dfs[i].rename(\n",
    "                        columns={\n",
    "                            'transmit.time': f'transmit.time.{scheme}',\n",
    "                            'arrival.time': f'arrival.time.{scheme}',\n",
    "                            'lost': f'lost.{scheme}',\n",
    "                            'excl': f'excl.{scheme}',\n",
    "                            'latency': f'latency.{scheme}',\n",
    "                        }, inplace=True\n",
    "                    )\n",
    "                df = pd.concat([df, *dfs], axis=1)\n",
    "                ### TODO 2\n",
    "                xs = list(itertools.combinations(range(len(schemes)), 2))\n",
    "                for x in xs:\n",
    "                    # f'lost.{schemes[x[0]]}.{schemes[x[1]]}'\n",
    "                    # f'lost.{schemes[x[0]]}'\n",
    "                    # f'lost.{schemes[x[1]]}'\n",
    "                    df[f'lost.{schemes[x[0]]}.{schemes[x[1]]}'] = df[f'lost.{schemes[x[0]]}'] & df[f'lost.{schemes[x[1]]}']\n",
    "                    df[f'excl.{schemes[x[0]]}.{schemes[x[1]]}'] = df[f'excl.{schemes[x[0]]}'] & df[f'excl.{schemes[x[1]]}']\n",
    "                    df[f'latency.{schemes[x[0]]}.{schemes[x[1]]}'] = df[[f'latency.{schemes[x[0]]}', f'latency.{schemes[x[1]]}']].min(axis=1)\n",
    "                fout1 = os.path.join(target_dir, f\"udp_{tag}_combo_loss_latency.csv\")\n",
    "                # print(\"output >>>\", fout1)\n",
    "                df.to_csv(fout1, index=False)\n",
    "                ### TODO 3\n",
    "                # colnames = list(df.columns)[3:]\n",
    "                colnames = []\n",
    "                data = []\n",
    "                for i, (dev, scheme) in enumerate(zip(devices, schemes)):\n",
    "                    _df = df[df[f'lost.{scheme}'] == False]\n",
    "                    # print(round(sum(df[f'lost.{scheme}']) / (len(df)+1e-9) * 100, 3))\n",
    "                    # print(round(sum(_df[f'excl.{scheme}']) / (len(_df)+1e-9) * 100, 3))\n",
    "                    loss = sum(df[f'lost.{scheme}']) / (len(df)+1e-9) * 100\n",
    "                    excl = sum(_df[f'excl.{scheme}']) / (len(_df)+1e-9) * 100\n",
    "                    latn = round(mean(_df[f'latency.{scheme}']), 6)\n",
    "                    mlatn = round(max(_df[f'latency.{scheme}']), 6)\n",
    "                    data = [*data, *[loss, excl, latn, mlatn]]\n",
    "                    colnames = [*colnames, *[f'lost.{scheme}', f'excl.{scheme}', f'latency.{scheme}', f'mlatency.{scheme}']]\n",
    "                    print(loss, excl, latn, mlatn, sep='\\t')\n",
    "                for x in xs:\n",
    "                    _df = df[df[f'lost.{schemes[x[0]]}.{schemes[x[1]]}'] == False]\n",
    "                    # print(round(sum(df[f'lost.{schemes[x[0]]}.{schemes[x[1]]}']) / (len(df)+1e-9) * 100, 3))\n",
    "                    # print(round(sum(_df[f'excl.{schemes[x[0]]}.{schemes[x[1]]}']) / (len(_df)+1e-9) * 100, 3))\n",
    "                    loss = sum(df[f'lost.{schemes[x[0]]}.{schemes[x[1]]}']) / (len(df)+1e-9) * 100\n",
    "                    excl = sum(_df[f'excl.{schemes[x[0]]}.{schemes[x[1]]}']) / (len(_df)+1e-9) * 100\n",
    "                    latn = round(mean(_df[f'latency.{schemes[x[0]]}.{schemes[x[1]]}']), 6)\n",
    "                    mlatn = round(max(_df[f'latency.{schemes[x[0]]}.{schemes[x[1]]}']), 6)\n",
    "                    data = [*data, *[loss, excl, latn, mlatn]]\n",
    "                    colnames = [*colnames, *[f'lost.{schemes[x[0]]}.{schemes[x[1]]}', f'excl.{schemes[x[0]]}.{schemes[x[1]]}', f'latency.{schemes[x[0]]}.{schemes[x[1]]}', f'mlatency.{schemes[x[0]]}.{schemes[x[1]]}']]\n",
    "                    print(loss, excl, latn, mlatn, sep='\\t')\n",
    "                fout2 = os.path.join(target_dir, f\"udp_{tag}_combo_statistics.csv\")\n",
    "                # print(\"output >>>\", fout2)\n",
    "                with open(fout2, \"w\", newline='') as fp:\n",
    "                    writer = csv.writer(fp)\n",
    "                    writer.writerow(colnames)\n",
    "                    writer.writerow(data)\n",
    "                t.toc()\n",
    "                ### TODO END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import csv\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "from tqdm import tqdm\n",
    "from pytictoc import TicToc\n",
    "import traceback\n",
    "from statistics import median\n",
    "from statistics import mean\n",
    "from statistics import mode\n",
    "from statistics import stdev\n",
    "from scipy import stats\n",
    "from scipy import signal\n",
    "import portion as P\n",
    "import math\n",
    "import random\n",
    "import itertools\n",
    "\n",
    "# ******************************* User Settings *******************************\n",
    "database = \"/home/wmnlab/D/database/\"\n",
    "dates = [\n",
    "        #  \"2023-02-04\",\n",
    "        #  \"2023-02-04#1\",\n",
    "         \"2023-02-04#2\",\n",
    "         ]\n",
    "devices = [\n",
    "    # \"sm00\",\n",
    "    # \"sm01\",\n",
    "    # \"sm02\",\n",
    "    # \"sm03\",\n",
    "    # \"sm04\",\n",
    "    # \"sm05\",\n",
    "    # \"sm06\",\n",
    "    # \"sm07\",\n",
    "    # \"sm08\",\n",
    "    # \"qc00\",\n",
    "    \"qc01\",\n",
    "    \"qc02\",\n",
    "    \"qc03\",\n",
    "]\n",
    "schemes = [\n",
    "    # \"B3\",\n",
    "    # \"B7\",\n",
    "    # \"B8\",\n",
    "    \"All@qc01\",\n",
    "    \"All@qc02\",\n",
    "    \"All@qc03\",\n",
    "]\n",
    "exps = {  # experiment_name: (number_of_experiment_rounds, list_of_experiment_round)\n",
    "            # If the list is None, it will not list as directories.\n",
    "            # If the list is empty, it will list all directories in the current directory by default.\n",
    "            # If the number of experiment times != the length of existing directories of list, it would trigger warning and skip the directory.\n",
    "    # \"_Bandlock_Udp_B3_B7_B8_RM500Q\": (1, [\"#01\",]),\n",
    "    # \"_Bandlock_Udp_B3_B7_B8_RM500Q\": (2, [\"#01\", \"#02\"]),\n",
    "    # \"_Bandlock_Udp_all_RM500Q\": (1, [\"#01\",]),\n",
    "    \"_Bandlock_Udp_all_RM500Q\": (2, [\"#01\", \"#02\"]),\n",
    "}\n",
    "\n",
    "INF = 2147483647\n",
    "LENGTH = 250\n",
    "DATA_RATE = 1000e3  # bits-per-second\n",
    "PKT_RATE = DATA_RATE / LENGTH / 8  # packets-per-second\n",
    "print(\"packet_rate (pps):\", PKT_RATE, \"\\n\")\n",
    "# *****************************************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for date in dates:\n",
    "    for expr, (times, traces) in exps.items():\n",
    "        for trace in traces:\n",
    "            target_dir = os.path.join(database, date, expr, \"combo\", trace)\n",
    "            makedir(target_dir)\n",
    "            for tag in [\"dnlk\", \"uplk\"]:\n",
    "            # for tag in [\"dnlk\",]:\n",
    "                print(\"------------------------------------------\")\n",
    "                print(date, expr, trace, tag)  \n",
    "                print(\"------------------------------------------\")\n",
    "                t = TicToc()\n",
    "                t.tic()\n",
    "                dfs = []\n",
    "                for i, (dev, scheme) in enumerate(zip(devices, schemes)):\n",
    "                    source_dir = os.path.join(database, date, expr, dev, trace, \"data\")\n",
    "                    dfs.append(pd.read_csv(os.path.join(source_dir, f\"udp_{tag}_loss_latency.csv\")))\n",
    "                ### TODO 1\n",
    "                st, et = [], []\n",
    "                for i, (dev, scheme) in enumerate(zip(devices, schemes)):\n",
    "                    st.append(dfs[i]['sequence.number'].array[0])\n",
    "                    et.append(dfs[i]['sequence.number'].array[-1])\n",
    "                st, et = max(st), min(et)\n",
    "                for i, (dev, scheme) in enumerate(zip(devices, schemes)):\n",
    "                    dfs[i] = dfs[i][(dfs[i]['sequence.number'] >= st) & (dfs[i]['sequence.number'] <= et)]\n",
    "                    dfs[i].reset_index(drop=True, inplace=True)\n",
    "                df = dfs[0][['sequence.number', 'Timestamp', 'Timestamp_epoch']]\n",
    "                for i, (dev, scheme) in enumerate(zip(devices, schemes)):\n",
    "                    # dfs[i] = dfs[i][['sequence.number', 'Timestamp', 'Timestamp_epoch', 'lost', 'excl', 'latency']]\n",
    "                    dfs[i] = dfs[i][['lost', 'excl', 'latency']]\n",
    "                    dfs[i].rename(\n",
    "                        columns={\n",
    "                            'lost': f'lost.{scheme}',\n",
    "                            'excl': f'excl.{scheme}',\n",
    "                            'latency': f'latency.{scheme}',\n",
    "                        }, inplace=True\n",
    "                    )\n",
    "                df = pd.concat([df, *dfs], axis=1)\n",
    "                ### TODO 2\n",
    "                xs = list(itertools.combinations(range(len(schemes)), 2))\n",
    "                for x in xs:\n",
    "                    # f'lost.{schemes[x[0]]}.{schemes[x[1]]}'\n",
    "                    # f'lost.{schemes[x[0]]}'\n",
    "                    # f'lost.{schemes[x[1]]}'\n",
    "                    df[f'lost.{schemes[x[0]]}.{schemes[x[1]]}'] = df[f'lost.{schemes[x[0]]}'] & df[f'lost.{schemes[x[1]]}']\n",
    "                    df[f'excl.{schemes[x[0]]}.{schemes[x[1]]}'] = df[f'excl.{schemes[x[0]]}'] & df[f'excl.{schemes[x[1]]}']\n",
    "                    df[f'latency.{schemes[x[0]]}.{schemes[x[1]]}'] = df[[f'latency.{schemes[x[0]]}', f'latency.{schemes[x[1]]}']].min(axis=1)\n",
    "                fout1 = os.path.join(target_dir, f\"udp_{tag}_combo_loss_latency.csv\")\n",
    "                # print(\"output >>>\", fout1)\n",
    "                df.to_csv(fout1, index=False)\n",
    "                ### TODO 3\n",
    "                # colnames = list(df.columns)[3:]\n",
    "                colnames = []\n",
    "                data = []\n",
    "                for i, (dev, scheme) in enumerate(zip(devices, schemes)):\n",
    "                    _df = df[df[f'lost.{scheme}'] == False]\n",
    "                    # print(round(sum(df[f'lost.{scheme}']) / (len(df)+1e-9) * 100, 3))\n",
    "                    # print(round(sum(_df[f'excl.{scheme}']) / (len(_df)+1e-9) * 100, 3))\n",
    "                    loss = sum(df[f'lost.{scheme}']) / (len(df)+1e-9) * 100\n",
    "                    excl = sum(_df[f'excl.{scheme}']) / (len(_df)+1e-9) * 100\n",
    "                    latn = round(mean(_df[f'latency.{scheme}']), 6)\n",
    "                    mlatn = round(max(_df[f'latency.{scheme}']), 6)\n",
    "                    data = [*data, *[loss, excl, latn, mlatn]]\n",
    "                    colnames = [*colnames, *[f'lost.{scheme}', f'excl.{scheme}', f'latency.{scheme}', f'mlatency.{scheme}']]\n",
    "                    print(loss, excl, latn, mlatn, sep='\\t')\n",
    "                for x in xs:\n",
    "                    _df = df[df[f'lost.{schemes[x[0]]}.{schemes[x[1]]}'] == False]\n",
    "                    # print(round(sum(df[f'lost.{schemes[x[0]]}.{schemes[x[1]]}']) / (len(df)+1e-9) * 100, 3))\n",
    "                    # print(round(sum(_df[f'excl.{schemes[x[0]]}.{schemes[x[1]]}']) / (len(_df)+1e-9) * 100, 3))\n",
    "                    loss = sum(df[f'lost.{schemes[x[0]]}.{schemes[x[1]]}']) / (len(df)+1e-9) * 100\n",
    "                    excl = sum(_df[f'excl.{schemes[x[0]]}.{schemes[x[1]]}']) / (len(_df)+1e-9) * 100\n",
    "                    latn = round(mean(_df[f'latency.{schemes[x[0]]}.{schemes[x[1]]}']), 6)\n",
    "                    mlatn = round(max(_df[f'latency.{schemes[x[0]]}.{schemes[x[1]]}']), 6)\n",
    "                    data = [*data, *[loss, excl, latn, mlatn]]\n",
    "                    colnames = [*colnames, *[f'lost.{schemes[x[0]]}.{schemes[x[1]]}', f'excl.{schemes[x[0]]}.{schemes[x[1]]}', f'latency.{schemes[x[0]]}.{schemes[x[1]]}', f'mlatency.{schemes[x[0]]}.{schemes[x[1]]}']]\n",
    "                    print(loss, excl, latn, mlatn, sep='\\t')\n",
    "                fout2 = os.path.join(target_dir, f\"udp_{tag}_combo_statistics.csv\")\n",
    "                # print(\"output >>>\", fout2)\n",
    "                with open(fout2, \"w\", newline='') as fp:\n",
    "                    writer = csv.writer(fp)\n",
    "                    writer.writerow(colnames)\n",
    "                    writer.writerow(data)\n",
    "                t.toc()\n",
    "                ### TODO END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
