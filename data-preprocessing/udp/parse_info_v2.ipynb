{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import csv\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "from tqdm.notebook import tqdm\n",
    "from pytictoc import TicToc\n",
    "import traceback\n",
    "from statistics import median\n",
    "from statistics import mean\n",
    "from statistics import mode\n",
    "from statistics import stdev\n",
    "from scipy import stats\n",
    "from scipy import signal\n",
    "import portion as P\n",
    "import swifter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makedir(dirpath, mode=0):  # mode=1: show message; mode=0: hide message\n",
    "    if os.path.isdir(dirpath):\n",
    "        if mode:\n",
    "            print(\"mkdir: cannot create directory '{}': directory has already existed.\".format(dirpath))\n",
    "        return\n",
    "    ### recursively make directory\n",
    "    _temp = []\n",
    "    while not os.path.isdir(dirpath):\n",
    "        _temp.append(dirpath)\n",
    "        dirpath = os.path.dirname(dirpath)\n",
    "    while _temp:\n",
    "        dirpath = _temp.pop()\n",
    "        print(\"mkdir\", dirpath)\n",
    "        os.mkdir(dirpath)\n",
    "\n",
    "def epoch_to_utc8(ts):\n",
    "    \"\"\"\n",
    "    Convert an epoch time into a readable format.\n",
    "    Switch from utc-0 into utc-8.\n",
    "    \n",
    "    Args:\n",
    "        ts (float): timestamp composed of datetimedec + microsecond (e.g., 1644051509.989306)\n",
    "    Returns:\n",
    "        (datetime.datetime): a readable timestamp (utc-8)\n",
    "    \"\"\"\n",
    "    return (dt.datetime.utcfromtimestamp(ts) + dt.timedelta(hours=8))\n",
    "\n",
    "def str_to_datetime(ts):\n",
    "    \"\"\"\n",
    "    Convert a timestamp string in microseconds or milliseconds into datetime.datetime\n",
    "\n",
    "    Args:\n",
    "        ts (str): timestamp string (e.g., 2022-09-29 16:24:58.252615)\n",
    "    Returns:\n",
    "        (datetime.datetime)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        ts_datetime = dt.datetime.strptime(ts, \"%Y-%m-%d %H:%M:%S.%f\")\n",
    "    except:\n",
    "        ts_datetime = dt.datetime.strptime(ts, \"%Y-%m-%d %H:%M:%S\")\n",
    "    return ts_datetime\n",
    "\n",
    "def datetime_to_str(ts):\n",
    "    \"\"\"\n",
    "    Convert a datetime timestamp in microseconds into str\n",
    "\n",
    "    Args:\n",
    "        ts (datetime.datetime): datetime timestamp (e.g., datetime.datetime(2022, 9, 29, 16, 24, 58, 252615))\n",
    "    Returns:\n",
    "        (str): timestamp string (e.g., 2022-09-29 16:24:58.252615)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        ts_string = dt.datetime.strftime(ts, \"%Y-%m-%d %H:%M:%S.%f\")\n",
    "    except:\n",
    "        ts_string = dt.datetime.strftime(ts, \"%Y-%m-%d %H:%M:%S\")\n",
    "    return ts_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class Payl:\n",
    "    LENGTH = 250              # (Bytes)\n",
    "    TAG = \"000425d401df5e76\"  # 2 71828 3 1415926 (hex)            : 8-bytes\n",
    "    OFS_TIME = (16, 24)       # epoch time of 'yyyy/mm/dd hh:mm:ss': 4-bytes\n",
    "    OFS_USEC = (24, 32)       # microsecond (usec)                 : 4-bytes\n",
    "    OFS_SEQN = (32, 40)       # sequence number (start from 1)     : 4-bytes\n",
    "\n",
    "class GParam:\n",
    "    TRANS = 4\n",
    "    RECV = 0\n",
    "    TCP = 6\n",
    "    UDP = 17\n",
    "    \n",
    "def epoch_to_utc8(ts):\n",
    "    \"\"\"\n",
    "    Convert an epoch time into a readable format.\n",
    "    Switch from utc-0 into utc-8.\n",
    "    \n",
    "    Args:\n",
    "        ts (float): timestamp composed of datetimedec + microsecond (e.g., 1644051509.989306)\n",
    "    Returns:\n",
    "        (datetime.datetime): a readable timestamp (utc-8)\n",
    "    \"\"\"\n",
    "    return (dt.datetime.utcfromtimestamp(ts) + dt.timedelta(hours=8))\n",
    "\n",
    "def parse_packet_info(fin, fout, term, direct, proto):   \n",
    "    new_header = [\"seq\", \"rpkg\", \"frame_id\", \"frame_time\", \"frame_time_epoch\", \"pyl_time\", \"pyl_time_epoch\"]\n",
    "    timestamp_list = []\n",
    "    seq_set = set()\n",
    "    # Open the CSV file for reading\n",
    "    with open(fin, 'r') as csvfile:\n",
    "        # Create a CSV reader\n",
    "        csvreader = csv.reader(csvfile, delimiter='@')\n",
    "\n",
    "        # Read the header row\n",
    "        header = next(csvreader)\n",
    "        # print(header)\n",
    "        \n",
    "        # Iterate through the rows in the CSV file\n",
    "        for content in tqdm(csvreader, ncols=1000):\n",
    "            # print(content)\n",
    "            row = {k: v for k, v in zip(header, content)}\n",
    "            \n",
    "            # server/client; uplink/downlink\n",
    "            if (term == \"server\" and direct == \"ul\") and int(row['sll.pkttype']) != GParam.RECV:\n",
    "                continue\n",
    "            elif (term == \"client\" and direct == \"ul\") and int(row['sll.pkttype']) != GParam.TRANS:\n",
    "                continue\n",
    "            elif (term == \"server\" and direct == \"dl\") and int(row['sll.pkttype']) != GParam.TRANS:\n",
    "                continue\n",
    "            elif (term == \"client\" and direct == \"dl\") and int(row['sll.pkttype']) != GParam.RECV:\n",
    "                continue\n",
    "            \n",
    "            # udp/tcp\n",
    "            if proto == \"udp\" and int(row['ip.proto']) != GParam.UDP:\n",
    "                continue\n",
    "            elif proto == \"tcp\" and int(row['ip.proto']) != GParam.TCP:\n",
    "                continue\n",
    "            \n",
    "            # check customized packet\n",
    "            if proto == \"udp\" and not ((int(row['udp.length']) > Payl.LENGTH) and (int(row['udp.length']) % Payl.LENGTH == 8)):\n",
    "                continue\n",
    "            elif proto == \"tcp\" and Payl.TAG not in row['tcp.payload']:\n",
    "                continue\n",
    "            \n",
    "            # print(content)\n",
    "            \n",
    "            payload = row['udp.payload']\n",
    "            rpkg_num = int(row['udp.length']) // Payl.LENGTH\n",
    "            offset = [s * Payl.LENGTH * 2 for s in list(range(rpkg_num))]  # 1-Byte == 2-hex-digits\n",
    "            \n",
    "            sequence_list = []\n",
    "            payload_time_list = []\n",
    "            payload_time_epoch_list = []\n",
    "            for ofs in offset:\n",
    "                try:\n",
    "                    datetimedec = int(payload[ofs + Payl.OFS_TIME[0] : ofs + Payl.OFS_TIME[1]], 16)\n",
    "                    microsec = int(payload[ofs + Payl.OFS_USEC[0] : ofs + Payl.OFS_USEC[1]], 16)\n",
    "                    seq = int(payload[ofs + Payl.OFS_SEQN[0] : ofs + Payl.OFS_SEQN[1]], 16)\n",
    "                except:\n",
    "                    print(traceback.format_exc())\n",
    "                    print(row['frame.time'])\n",
    "                    print(payload)\n",
    "                    sys.exit(1)\n",
    "                \n",
    "                payload_time = epoch_to_utc8(datetimedec + microsec * 1e-6)\n",
    "                \n",
    "                sequence_list.append(seq)\n",
    "                payload_time_list.append(payload_time)\n",
    "                payload_time_epoch_list.append(datetimedec + microsec * 1e-6)\n",
    "            \n",
    "            # print(\"rpkg\", rpkg_num)\n",
    "            # print(\"frame_id\", int(row['frame.number']))\n",
    "            # print(\"frame_time\", pd.to_datetime(row['frame.time']).tz_localize(None))\n",
    "            # print(\"frame_time_epoch\", float(row['frame.time_epoch']))\n",
    "            # print(\"seq\", sequence_list)\n",
    "            # print(\"pyl_time\", payload_time_list)\n",
    "            # print(\"pyl_time_epoch\", payload_time_epoch_list)\n",
    "            \n",
    "            for (seq, pyl_time, pyl_time_epoch) in zip(sequence_list, payload_time_list, payload_time_epoch_list):\n",
    "                if (seq, pyl_time_epoch) not in seq_set:\n",
    "                    timestamp_list.append([seq, rpkg_num, int(row['frame.number']), pd.to_datetime(row['frame.time']).tz_localize(None), float(row['frame.time_epoch']), pyl_time, pyl_time_epoch])\n",
    "                    seq_set.add((seq, pyl_time_epoch))\n",
    "\n",
    "    # print(seq_set)\n",
    "    # print(timestamp_list)\n",
    "\n",
    "    timestamp_list = sorted(timestamp_list, key = lambda v : v[0])\n",
    "\n",
    "    print(\"output >>>\", fout)\n",
    "    with open(fout, 'w', newline=\"\") as fp:\n",
    "        writer = csv.writer(fp)\n",
    "        writer.writerow(new_header)\n",
    "        writer.writerows(timestamp_list)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jackbedford/Desktop/MOXA/testset/server_pcap_BL_sm00_3200_3201_2023-06-12_16-38-58_sock.csv\n",
      "/Users/jackbedford/Desktop/MOXA/testset/client_pcap_BL_sm00_3200_3201_2023-06-12_16-38-57_sock.csv\n",
      "/Users/jackbedford/Desktop/MOXA/testset/server_pcap_BL_sm00_3200_3201_2023-06-12_16-38-58_sock.csv\n",
      "/Users/jackbedford/Desktop/MOXA/testset/client_pcap_BL_sm00_3200_3201_2023-06-12_16-38-57_sock.csv\n"
     ]
    }
   ],
   "source": [
    "testdir = \"/Users/jackbedford/Desktop/MOXA/testset\"\n",
    "\n",
    "ul_s_file = os.path.join(testdir, [s for s in os.listdir(testdir) if s.startswith((\"server_pcap_BL\", \"server_pcap_UL\")) and s.endswith(\".csv\")][0])\n",
    "ul_c_file = os.path.join(testdir, [s for s in os.listdir(testdir) if s.startswith((\"client_pcap_BL\", \"client_pcap_UL\")) and s.endswith(\".csv\")][0])\n",
    "dl_s_file = os.path.join(testdir, [s for s in os.listdir(testdir) if s.startswith((\"server_pcap_BL\", \"server_pcap_DL\")) and s.endswith(\".csv\")][0])\n",
    "dl_c_file = os.path.join(testdir, [s for s in os.listdir(testdir) if s.startswith((\"client_pcap_BL\", \"client_pcap_DL\")) and s.endswith(\".csv\")][0])\n",
    "print(ul_s_file, ul_c_file, dl_s_file, dl_c_file, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f31d5f3729734695861180dc2224d780",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output >>> udp_uplk_server_pkt_brief.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b19edc00c1ba4401804d75f419e01d1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output >>> udp_uplk_client_pkt_brief.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b18d4ea5d6e74f929f13620aa096948a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output >>> udp_dnlk_server_pkt_brief.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e9572bd8dc54a6db203f3332b6c548b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output >>> udp_dnlk_client_pkt_brief.csv\n"
     ]
    }
   ],
   "source": [
    "parse_packet_info(ul_s_file, \"udp_uplk_server_pkt_brief.csv\", \"server\", \"ul\", \"udp\")\n",
    "parse_packet_info(ul_c_file, \"udp_uplk_client_pkt_brief.csv\", \"client\", \"ul\", \"udp\")\n",
    "parse_packet_info(dl_s_file, \"udp_dnlk_server_pkt_brief.csv\", \"server\", \"dl\", \"udp\")\n",
    "parse_packet_info(dl_c_file, \"udp_dnlk_client_pkt_brief.csv\", \"client\", \"dl\", \"udp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [\"udp_uplk_server_pkt_brief.csv\", \"udp_uplk_client_pkt_brief.csv\", \"udp_dnlk_server_pkt_brief.csv\", \"udp_dnlk_client_pkt_brief.csv\"]\n",
    "\n",
    "st_t = []\n",
    "ed_t = []\n",
    "for file in files:\n",
    "    df = pd.read_csv(file)\n",
    "    df['frame_time'] = pd.to_datetime(df['frame_time'])\n",
    "    st_t.append(df.iloc[0]['frame_time'] - pd.Timedelta(seconds=5))\n",
    "    ed_t.append(df.iloc[-1]['frame_time'] + pd.Timedelta(seconds=5))\n",
    "    del df\n",
    "\n",
    "st_t = max(st_t)\n",
    "ed_t = min(ed_t)\n",
    "\n",
    "for file in files:\n",
    "    df = pd.read_csv(file)\n",
    "    df['frame_time'] = pd.to_datetime(df['frame_time'])\n",
    "    df = df[(df['frame_time'] > st_t) & (df['frame_time'] < ed_t)]\n",
    "    df.to_csv(file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "moxa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
