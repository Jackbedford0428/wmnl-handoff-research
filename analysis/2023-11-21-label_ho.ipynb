{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "from collections import namedtuple\n",
    "from collections import defaultdict\n",
    "from pprint import pprint\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "# Configure display options\n",
    "pd.set_option('display.max_columns', 200)\n",
    "pd.set_option('display.max_rows', 200)\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "# Add project directory to sys.path\n",
    "# pdir = os.path.abspath(os.path.join(os.getcwd(), '.'))\n",
    "# sys.path.insert(1, pdir)\n",
    "# from myutils import *\n",
    "\n",
    "# Other module imports\n",
    "import ast, math, swifter, csv, json, itertools as it, portion as P\n",
    "\n",
    "# Set plot style\n",
    "# plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ************************************************* unify data format *************************************************\n",
    "\n",
    "def set_data(df, mode='pcap', tz=0):\n",
    "    def nr_serv_cel(row):\n",
    "        pos = row.serv_cel_pos\n",
    "        if pos == 255:\n",
    "            return 65535, -160, -50\n",
    "        else:\n",
    "            return row[f'PCI{pos}'], row[f'RSRP{pos}'], row[f'RSRQ{pos}']\n",
    "    \n",
    "    if mode == 'pcap':\n",
    "        common_column_names = ['seq', 'rpkg', 'frame_id', 'Timestamp', 'lost', 'excl', 'latency', 'xmit_time', 'arr_time']\n",
    "        \n",
    "        if df.empty:\n",
    "            return pd.DataFrame(columns=common_column_names)\n",
    "        \n",
    "        date_columns = ['Timestamp', 'xmit_time', 'arr_time']\n",
    "        df[date_columns] = df[date_columns].apply(pd.to_datetime)\n",
    "        df[['seq', 'rpkg', 'frame_id']] = df[['seq', 'rpkg', 'frame_id']].astype('Int32')\n",
    "        df[['latency']] = df[['latency']].astype('float32')\n",
    "        df[['lost', 'excl']] = df[['lost', 'excl']].astype('boolean')\n",
    "\n",
    "    if mode in ['lte', 'nr']:\n",
    "        common_column_names = [\n",
    "            'Timestamp', 'type_id', 'PCI', 'RSRP', 'RSRQ', 'serv_cel_index', 'EARFCN', 'NR_ARFCN', \n",
    "            'num_cels', 'num_neigh_cels', 'serv_cel_pos', 'PCI0', 'RSRP0', 'RSRQ0',\n",
    "        ]\n",
    "        \n",
    "        if df.empty:\n",
    "            return pd.DataFrame(columns=common_column_names)\n",
    "        \n",
    "        if mode == 'lte':\n",
    "            columns_mapping = {\n",
    "                'RSRP(dBm)': 'RSRP',\n",
    "                'RSRQ(dB)': 'RSRQ',\n",
    "                'Serving Cell Index': 'serv_cel_index',\n",
    "                'Number of Neighbor Cells': 'num_neigh_cels',\n",
    "                'Number of Detected Cells': 'num_cels',\n",
    "            }\n",
    "            columns_order = [*common_column_names, *df.columns[df.columns.get_loc('PCI1'):].tolist()]\n",
    "            \n",
    "            df = df.rename(columns=columns_mapping).reindex(columns_order, axis=1)\n",
    "            df['serv_cel_index'] = np.where(df['serv_cel_index'] == '(MI)Unknown', '3_SCell', df['serv_cel_index'])\n",
    "            df['num_cels'] = df['num_neigh_cels'] + 1\n",
    "            df['type_id'] = 'LTE_PHY'\n",
    "\n",
    "        if mode == 'nr':\n",
    "            columns_mapping = {\n",
    "                'Raster ARFCN': 'NR_ARFCN',\n",
    "                'Serving Cell Index': 'serv_cel_pos',\n",
    "                'Num Cells': 'num_cels',\n",
    "            }\n",
    "            columns_order = [*common_column_names, *df.columns[df.columns.get_loc('PCI1'):].tolist()]\n",
    "            \n",
    "            df = df.rename(columns=columns_mapping).reindex(columns_order, axis=1)\n",
    "            df[['PCI', 'RSRP', 'RSRQ']] = df.apply(nr_serv_cel, axis=1, result_type='expand')\n",
    "            df['serv_cel_index'] = np.where(df['serv_cel_pos'] == 255, df['serv_cel_index'], 'PSCell')\n",
    "            df['num_neigh_cels'] = np.where(df['serv_cel_pos'] == 255, df['num_cels'], df['num_cels'] - 1)\n",
    "            df['type_id'] = '5G_NR_ML1'\n",
    "        \n",
    "        df['Timestamp'] = pd.to_datetime(df['Timestamp']) + pd.Timedelta(hours=tz)\n",
    "        df[['type_id', 'serv_cel_index']] = df[['type_id', 'serv_cel_index']].astype('category')\n",
    "        df[['EARFCN', 'NR_ARFCN']] = df[['EARFCN', 'NR_ARFCN']].astype('Int32')\n",
    "        df[['num_cels', 'num_neigh_cels', 'serv_cel_pos']] = df[['num_cels', 'num_neigh_cels', 'serv_cel_pos']].astype('UInt8')\n",
    "\n",
    "        for tag in df.columns:\n",
    "            if tag.startswith('PCI'):\n",
    "                df[tag] = df[tag].astype('Int32')\n",
    "            if tag.startswith(('RSRP', 'RSRQ')):\n",
    "                df[tag] = df[tag].astype('float32')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## handover parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ************************************************* Sheng-Ru Latest Version (09-25) add try except (10-27) add nr arfcn (11-13) add BSID (11-21) *************************************************\n",
    "\n",
    "def parse_mi_ho(df, tz=8):\n",
    "\n",
    "    # df = pd.read_csv(f)\n",
    "    df[\"Timestamp\"] = df[\"Timestamp\"].swifter.apply(lambda x: pd.to_datetime(x) + dt.timedelta(hours=tz))\n",
    "    nr_pci = 'O'\n",
    "    nr_arfcn = 0\n",
    "    scells = []\n",
    "\n",
    "    def NR_OTA(idx):\n",
    "\n",
    "        if df[\"type_id\"].iloc[idx] == \"5G_NR_RRC_OTA_Packet\": return True\n",
    "        else: return False\n",
    "    \n",
    "    def LTE_SERV_INFO(idx):\n",
    "\n",
    "        if df[\"type_id\"].iloc[idx] == \"LTE_RRC_Serv_Cell_Info\": return True\n",
    "        else: return False\n",
    "    \n",
    "\n",
    "    def find_1st_after(start_idx, target, look_after=1):\n",
    "        for j in range(start_idx, len(df)):\n",
    "            t_ = df[\"Timestamp\"].iloc[j]\n",
    "            if NR_OTA(j) or LTE_SERV_INFO(j):\n",
    "                continue\n",
    "            if (t_ - t).total_seconds() > look_after:\n",
    "                return None, None\n",
    "            if df[target].iloc[j] not in [0,'0'] and not np.isnan(df[target].iloc[j]):\n",
    "                return t_, j\n",
    "        return None, None\n",
    "    \n",
    "    def find_1st_before(start_idx, target, look_before=1):\n",
    "        for j in range(start_idx, -1, -1):\n",
    "            t_ = df[\"Timestamp\"].iloc[j]\n",
    "            if NR_OTA(j) or LTE_SERV_INFO(j):\n",
    "                continue\n",
    "            if (t - t_).total_seconds() > look_before:\n",
    "                return None, None\n",
    "            if df[target].iloc[j] not in [0,'0'] and not np.isnan(df[target].iloc[j]):\n",
    "                return t_, j\n",
    "        return None, None\n",
    "    \n",
    "    def find_1st_before_with_special_value(start_idx, target, target_value, look_before=1):\n",
    "        for j in range(start_idx, -1, -1):\n",
    "            t_ = df[\"Timestamp\"].iloc[j]\n",
    "            if NR_OTA(j) or LTE_SERV_INFO(j):\n",
    "                continue\n",
    "            if (t - t_).total_seconds() > look_before:\n",
    "                return None, None\n",
    "            if df[target].iloc[j] in [target_value] and not np.isnan(df[target].iloc[j]):\n",
    "                return t_, j\n",
    "        return None, None\n",
    "    \n",
    "    def find_in_D_exact(targets):\n",
    "\n",
    "        l = []\n",
    "        # In l : (second, ho_type)\n",
    "        for target in targets:\n",
    "            for ho in D[target]:\n",
    "                l.append(((t - ho.start).total_seconds(), target))\n",
    "\n",
    "        if len(l) != 0:\n",
    "            for x in l:\n",
    "                if (x[0]== 0):\n",
    "                    return x[1]\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def find_in_D_first_before(targets, look_before=1):\n",
    "\n",
    "        l = []\n",
    "        # In l : (second, ho_type)\n",
    "        for target in targets:\n",
    "            for ho in D[target]:\n",
    "                try:\n",
    "                    l.append(((t - ho.end).total_seconds(), target, ho))\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "        if len(l) != 0:\n",
    "            closest = min(filter(lambda x: x[0] > 0, l), key=lambda x: x[0])\n",
    "            if 0 <= closest[0] < look_before:\n",
    "                return closest[1], closest[2]\n",
    "        \n",
    "        return None, None\n",
    "    \n",
    "    HO = namedtuple('HO',['start', 'end', 'others', 'trans'], defaults=[None,None,'',''])\n",
    "    \n",
    "    D = {\n",
    "        'Conn_Rel':[], \n",
    "        'Conn_Req':[], # Setup\n",
    "        'LTE_HO': [], # LTE -> newLTE\n",
    "        'MN_HO': [], # LTE + NR -> newLTE + NR\n",
    "        'MN_HO_to_eNB': [], # LTE + NR -> newLTE\n",
    "        'SN_setup': [], # LTE -> LTE + NR => NR setup\n",
    "        'SN_Rel': [], # LTE + NR -> LTE\n",
    "        'SN_HO': [], # LTE + NR -> LTE + newNR  \n",
    "        'RLF_II': [],\n",
    "        'RLF_III': [],\n",
    "        'SCG_RLF': [],\n",
    "        'Add_SCell': [],\n",
    "        }\n",
    "\n",
    "    for i in range(len(df)):\n",
    "\n",
    "        # Pass NR RRC packet. In NSA mode, LTE RRC packet include NR packet message.\n",
    "        if NR_OTA(i) or LTE_SERV_INFO(i):\n",
    "            continue\n",
    "\n",
    "        others = ''\n",
    "        t = df[\"Timestamp\"].iloc[i]\n",
    "\n",
    "        if df[\"rrcConnectionRelease\"].iloc[i] == 1:\n",
    "            D['Conn_Rel'].append(HO(start=t))\n",
    "            nr_pci = 'O'\n",
    "\n",
    "        if df[\"rrcConnectionRequest\"].iloc[i] == 1:\n",
    "            \n",
    "            # Define end of rrcConnectionRequest to be rrcConnectionReconfigurationComplete or securityModeComplete.\n",
    "            a = find_1st_after(i, 'rrcConnectionReconfigurationComplete',look_after=2)[0]\n",
    "            b = find_1st_after(i, 'securityModeComplete',look_after=2)[0]\n",
    "            if a is None and b is None: end = None\n",
    "            elif a is None and b is not None: end = b\n",
    "            elif a is not None and b is None: end = a \n",
    "            else: end = a if a > b else b\n",
    "            \n",
    "            serv_cell, serv_freq = df[\"PCI\"].iloc[i], int(df[\"Freq\"].iloc[i])\n",
    "            trans = f'? -> ({serv_cell}, {serv_freq})'\n",
    "            D['Conn_Req'].append(HO(start=t,end=end,trans=trans))\n",
    "            nr_pci = 'O'\n",
    "        \n",
    "        if df[\"lte-rrc.t304\"].iloc[i] == 1:\n",
    "            \n",
    "            end, _ = find_1st_after(i, 'rrcConnectionReconfigurationComplete')\n",
    "            serv_cell, target_cell = df[\"PCI\"].iloc[i], int(df['lte_targetPhysCellId'].iloc[i])\n",
    "            serv_freq, target_freq = int(df[\"Freq\"].iloc[i]), int(df['dl-CarrierFreq'].iloc[i])\n",
    "\n",
    "            if df[\"SCellToAddMod-r10\"].iloc[i] == 1:\n",
    "                n =len(str(df[\"SCellIndex-r10.1\"].iloc[i]).split('@'))\n",
    "                others += f' Set up {n} SCell.'\n",
    "            else:\n",
    "                scells = []\n",
    "            \n",
    "            if serv_freq != target_freq:\n",
    "                a,b = find_1st_before(i, \"rrcConnectionReestablishmentRequest\", 1)\n",
    "                others += \" Inter frequency HO.\"\n",
    "                if a is not None:\n",
    "                    others += \" Near after RLF.\"\n",
    "                \n",
    "            if df[\"nr-rrc.t304\"].iloc[i] == 1 and df[\"dualConnectivityPHR: setup (1)\"].iloc[i] == 1:\n",
    "                \n",
    "                if serv_cell == target_cell and serv_freq == target_freq:\n",
    "\n",
    "                    a, _ = find_1st_before(i, \"rrcConnectionReestablishmentRequest\", 2)\n",
    "                    \n",
    "                    if a is not None:\n",
    "\n",
    "                        ho_type, ho = find_in_D_first_before(['RLF_II', 'RLF_III'], 2)\n",
    "                        try:\n",
    "                            others += f' Near after RLF of trans: {ho.trans}.'\n",
    "                        except:\n",
    "                            others += f' Near after RLF.'\n",
    "\n",
    "                    else:\n",
    "                        \n",
    "                        ho_type, _ = find_in_D_first_before(['MN_HO_to_eNB', 'SN_Rel'], 2)\n",
    "                        if ho_type is not None:\n",
    "                            others += f' Near after {ho_type}.'\n",
    "                    orig_serv = (nr_pci, nr_arfcn) if nr_pci != 'O' else 'O'\n",
    "                    nr_pci = int(df['nr_physCellId'].iloc[i])\n",
    "                    nr_arfcn = int(df['absoluteFrequencySSB'].iloc[i])\n",
    "                    trans = f'({serv_cell}, {serv_freq}) | {orig_serv} -> ({nr_pci}, {nr_arfcn})'\n",
    "                    D['SN_setup'].append(HO(start=t, end=end, others=others, trans=trans))\n",
    "\n",
    "                else:\n",
    "                    \n",
    "                    nr_pci = int(df['nr_physCellId'].iloc[i])\n",
    "                    trans = f'({serv_cell}, {serv_freq}) -> ({target_cell}, {target_freq}) | ({nr_pci}, {nr_arfcn})'\n",
    "                    D['MN_HO'].append(HO(start=t, end=end, others=others, trans=trans))\n",
    "\n",
    "            else:\n",
    "                \n",
    "                if serv_cell == target_cell and serv_freq == target_freq:\n",
    "\n",
    "                    a, b = find_1st_before(i, \"scgFailureInformationNR-r15\")\n",
    "                    if a is not None:\n",
    "                        others += \" Caused by scg-failure.\"\n",
    "                    \n",
    "                    orig_serv = (nr_pci, nr_arfcn) if nr_pci != 'O' else 'O'\n",
    "                    nr_pci = 'O'\n",
    "                    trans = f'({serv_cell}, {serv_freq}) | {orig_serv} -> {nr_pci}'\n",
    "                    D['SN_Rel'].append(HO(start=t, end=end, others=others, trans=trans))\n",
    "                    \n",
    "                else:\n",
    "\n",
    "                    a, _ = find_1st_before(i,\"rrcConnectionSetup\",3)\n",
    "                    if a is not None:\n",
    "                        others += ' Near After connection setup.'\n",
    "                    if nr_pci == 'O':\n",
    "                        trans = f'({serv_cell}, {serv_freq}) -> ({target_cell}, {target_freq}) | {nr_pci}'\n",
    "                        D['LTE_HO'].append(HO(start=t, end=end, others=others, trans=trans))\n",
    "                    else:\n",
    "                        orig_serv = (nr_pci, nr_arfcn) if nr_pci != 'O' else 'O'\n",
    "                        nr_pci = 'O'\n",
    "                        trans = f'({serv_cell}, {serv_freq}) -> ({target_cell}, {target_freq}) | {orig_serv} -> {nr_pci}'\n",
    "                        D['MN_HO_to_eNB'].append(HO(start=t, end=end, others=others, trans=trans))\n",
    "\n",
    "\n",
    "        if df[\"nr-rrc.t304\"].iloc[i] == 1 and not df[\"dualConnectivityPHR: setup (1)\"].iloc[i] == 1:\n",
    "\n",
    "            end, _ = find_1st_after(i,'rrcConnectionReconfigurationComplete')\n",
    "        \n",
    "            serv_cell, serv_freq = df[\"PCI\"].iloc[i], int(df[\"Freq\"].iloc[i])\n",
    "            orig_serv = (nr_pci, nr_arfcn) if nr_pci != 'O' else 'O'\n",
    "            nr_pci = int(df['nr_physCellId'].iloc[i])\n",
    "            nr_arfcn = int(df['absoluteFrequencySSB'].iloc[i])\n",
    "            trans = f'({serv_cell}, {serv_freq}) | {orig_serv} -> ({nr_pci}, {nr_arfcn})'\n",
    "            D['SN_HO'].append(HO(start=t,end=end,trans=trans))\n",
    "\n",
    "\n",
    "        if df[\"rrcConnectionReestablishmentRequest\"].iloc[i] == 1:\n",
    "\n",
    "            end1, _ = find_1st_after(i, 'rrcConnectionReestablishmentComplete', look_after=1)\n",
    "            b, _ = find_1st_after(i, 'rrcConnectionReestablishmentReject', look_after=1)\n",
    "            end2, _ = find_1st_after(i, 'securityModeComplete',look_after=3)\n",
    "\n",
    "            others += ' ' + df[\"reestablishmentCause\"].iloc[i] + '.'\n",
    "            scells = []\n",
    "\n",
    "            c, _ = find_1st_before(i, 'scgFailureInformationNR-r15', 1)\n",
    "            if c != None:\n",
    "                others  += ' caused by scgfailure.'\n",
    "                \n",
    "            serv_cell, rlf_cell = df[\"PCI\"].iloc[i], int(df['physCellId.3'].iloc[i])\n",
    "            serv_freq = int(df['Freq'].iloc[i])\n",
    "            \n",
    "            # Type II & Type III\n",
    "            if end1 is not None: \n",
    "\n",
    "                orig_serv = (nr_pci, nr_arfcn) if nr_pci != 'O' else 'O'\n",
    "                nr_pci = 'O'\n",
    "                _, idx = find_1st_before_with_special_value(i, 'PCI', rlf_cell, look_before=10)\n",
    "                try:\n",
    "                    rlf_freq = int(df['Freq'].iloc[idx])\n",
    "                except:\n",
    "                    rlf_freq = 0\n",
    "                trans = f'({rlf_cell}, {rlf_freq}) -> ({serv_cell}, {serv_freq}) | {orig_serv} -> {nr_pci}'\n",
    "                D['RLF_II'].append(HO(start=t,end=end1,others=others,trans=trans))\n",
    "\n",
    "            elif b is not None and end2 is not None:\n",
    "                \n",
    "                orig_serv = (nr_pci, nr_arfcn) if nr_pci != 'O' else 'O'\n",
    "                nr_pci = 'O'\n",
    "                _, idx = find_1st_before_with_special_value(i, 'PCI', rlf_cell, look_before=10)\n",
    "                try:\n",
    "                    rlf_freq = int(df['Freq'].iloc[idx])\n",
    "                except:\n",
    "                    rlf_freq = 0\n",
    "\n",
    "                _, idx = find_1st_after(i, \"rrcConnectionRequest\", 2)\n",
    "                recon_cell, recon_freq = df['PCI'].iloc[idx], int(float(df['Freq'].iloc[idx]))\n",
    "                \n",
    "                trans = f'({rlf_cell}, {rlf_freq}) -> ({recon_cell}, {recon_freq}) | {orig_serv} -> {nr_pci}'\n",
    "                D['RLF_III'].append(HO(start=t,end=end2,others=others,trans=trans))\n",
    "                \n",
    "            else:\n",
    "                others+=' No end.'\n",
    "                D['RLF_II'].append(HO(start=t,others=others))\n",
    "                print('No end for RLF')\n",
    "\n",
    "        if df[\"scgFailureInformationNR-r15\"].iloc[i] == 1:\n",
    "\n",
    "            others += ' ' + df[\"failureType-r15\"].iloc[i] + '.'\n",
    "            a, idx1 = find_1st_after(i, \"rrcConnectionReestablishmentRequest\", look_after=1)\n",
    "            b, idx2 = find_1st_after(i, \"lte-rrc.t304\", look_after=10)\n",
    "\n",
    "            if a is not None:\n",
    "\n",
    "                end1, _ = find_1st_after(idx1, 'rrcConnectionReestablishmentComplete', look_after=1)\n",
    "                b, _ = find_1st_after(idx1, 'rrcConnectionReestablishmentReject', look_after=1)\n",
    "                end2 = find_1st_after(idx1, 'securityModeComplete',look_after=3)[0]\n",
    "\n",
    "                others += ' Result in rrcReestablishment.'\n",
    "                    \n",
    "                # Type II & Type III Result\n",
    "                if end1 is not None: \n",
    "                    D['SCG_RLF'].append(HO(start=t,end=end1,others=others))\n",
    "                elif b is not None and end2 is not None: \n",
    "                    D['SCG_RLF'].append(HO(start=t,end=end2,others=others))\n",
    "                else:\n",
    "                    others += ' No end.'\n",
    "                    D['SCG_RLF'].append(HO(start=t,others=others))\n",
    "                    print('No end for scg failure result in rrcReestablishment.')\n",
    "\n",
    "            elif b is not None:\n",
    "\n",
    "                end, _ = find_1st_after(idx2, 'rrcConnectionReconfigurationComplete')\n",
    "                serv_cell, target_cell = df[\"PCI\"].iloc[idx2], df['lte_targetPhysCellId'].iloc[idx2]\n",
    "                serv_freq, target_freq = int(df[\"Freq\"].iloc[idx2]), df['dl-CarrierFreq'].iloc[idx2]\n",
    "                others += ' Result in gNB release.'\n",
    "                # We do not change nr_pci here. Instead, we will change it at gNB_Rel event.\n",
    "                orig_serv = (nr_pci, nr_arfcn) if nr_pci != 'O' else 'O'\n",
    "                trans = f'({serv_cell}, {serv_freq}) | {orig_serv} -> O'\n",
    "                \n",
    "                if serv_cell == target_cell and serv_freq == target_freq:\n",
    "                    D['SCG_RLF'].append(HO(start=t,end=end,others=others,trans=trans))\n",
    "                else:\n",
    "                    others += ' Weird gNB release.'\n",
    "                    print('Weird for scg failure result in gNb Release.')\n",
    "                    D['SCG_RLF'].append(HO(start=t,end=end,others=others,trans=trans))                  \n",
    "\n",
    "            else:\n",
    "\n",
    "                print('No end for scg failure.')\n",
    "                others += ' No end.'\n",
    "                D['SCG_RLF'].append(HO(start=t,others=others))\n",
    "        \n",
    "        if df['SCellToAddMod-r10'].iloc[i] == 1 and df['physCellId-r10'].iloc[i] != 'nr or cqi report':\n",
    "\n",
    "            others = ''\n",
    "            pcis = str(df[\"physCellId-r10\"].iloc[i]).split('@')\n",
    "            freqs = str(df[\"dl-CarrierFreq-r10\"].iloc[i]).split('@')\n",
    "            orig_scells = scells\n",
    "            scells = [(int(float(pci)), int(float(freq))) for pci, freq in zip(pcis, freqs)]\n",
    "\n",
    "            others += f' Set up {len(scells)} SCell.'\n",
    "            trans = f'{orig_scells} -> {scells}'\n",
    "\n",
    "            end, _ = find_1st_after(i,'rrcConnectionReconfigurationComplete')\n",
    "            \n",
    "            a, _ = find_1st_before(i, \"rrcConnectionReestablishmentRequest\", 3)\n",
    "            if a is not None:\n",
    "                others += ' Near after RLF.'\n",
    "\n",
    "            a = find_in_D_exact(['LTE_HO', 'MN_HO', 'MN_HO_to_eNB', 'SN_setup', 'SN_Rel'])\n",
    "            if a is not None:\n",
    "                others += f' With {a}.'\n",
    "\n",
    "            D['Add_SCell'].append(HO(start=t,end=end,others=others, trans=trans))\n",
    "    \n",
    "    return D\n",
    "\n",
    "# ************************************************* parse into readable dataframe *************************************************\n",
    "\n",
    "def mi_parse_handover(df, tz=8, radical=True, endfill=False):\n",
    "    \n",
    "    def parse_trans(item):\n",
    "        \n",
    "        chunk = item.split(' | ')\n",
    "        \n",
    "        if len(chunk) == 1:\n",
    "            s_src = np.nan\n",
    "            s_tgt = np.nan\n",
    "            if chunk[0] == '':\n",
    "                m_src = np.nan\n",
    "                m_tgt = np.nan\n",
    "            elif chunk[0][0] == '?':\n",
    "                m_src = np.nan\n",
    "                m_tgt = chunk[0].split(' -> ')[1]\n",
    "            else:\n",
    "                m_src = chunk[0].split(' -> ')[0]\n",
    "                m_tgt = chunk[0].split(' -> ')[1]\n",
    "        else:\n",
    "            if chunk[1] == 'O':\n",
    "                s_src = np.nan\n",
    "                s_tgt = np.nan\n",
    "            else:\n",
    "                chunk1 = chunk[1].split(' -> ')\n",
    "                if len(chunk1) == 1:\n",
    "                    s_src = chunk1[0]\n",
    "                    s_tgt = np.nan\n",
    "                else:\n",
    "                    s_src = chunk1[0] if chunk1[0] != 'O' else np.nan\n",
    "                    s_tgt = chunk1[1] if chunk1[1] != 'O' else np.nan\n",
    "                \n",
    "            chunk1 = chunk[0].split(' -> ')\n",
    "            if len(chunk1) == 1:\n",
    "                m_src = chunk1[0]\n",
    "                m_tgt = np.nan\n",
    "            else:\n",
    "                m_src = chunk1[0]\n",
    "                m_tgt = chunk1[1]\n",
    "                \n",
    "        return m_src, m_tgt, s_src, s_tgt\n",
    "    \n",
    "    key_mapping = {\n",
    "        'Conn_Rel': 'CXNR',\n",
    "        'Conn_Req': 'CXNS',\n",
    "        'LTE_HO': 'LTEH',\n",
    "        'MN_HO': 'MCGH',\n",
    "        'MN_HO_to_eNB': 'SCGR-II',\n",
    "        'SN_setup': 'SCGA',\n",
    "        'SN_Rel': 'SCGR-I',\n",
    "        'SN_HO': 'SCGM',\n",
    "        'RLF_II': 'MCGF',\n",
    "        'RLF_III': 'NASR',\n",
    "        'SCG_RLF': 'SCGF',\n",
    "        'Add_SCell': 'SCLA'\n",
    "    }\n",
    "    \n",
    "    D = parse_mi_ho(df, tz)\n",
    "    \n",
    "    # rename as acronym\n",
    "    new_D = {key_mapping.get(key, key): value for key, value in D.items()}\n",
    "    \n",
    "    if df.empty:\n",
    "        selected_cols = ['m_src1', 'm_tgt1', 's_src1', 's_tgt1', 'PCI', 'Cell Identity', 'eNB_ID', 'next_eNB_ID', 'Band ID', 'next_BID', 'DL frequency', 'UL frequency', 'DL bandwidth', 'UL bandwidth', 'TAC', 'MCC', 'MNC']\n",
    "        table = pd.DataFrame(columns=['type', 'start', 'end', 'others', 'm_src', 'm_tgt', 's_src', 's_tgt', 'category', 'inter-eNB', 'inter-gNB', 'inter-Freq', 'band_cng', 'inter-RAT', '4G_5G', 'cause', 'near_before_RLF', *selected_cols])\n",
    "        print('Empty RRC File!!!')\n",
    "        return table, new_D\n",
    "    \n",
    "    table = pd.DataFrame()\n",
    "    for key, lst in new_D.items():\n",
    "        table1 = pd.DataFrame(lst, index=[key]*len(lst)).reset_index(names='type')\n",
    "        table = pd.concat([table, table1], ignore_index=True)\n",
    "    \n",
    "    if table.empty:\n",
    "        selected_cols = ['m_src1', 'm_tgt1', 's_src1', 's_tgt1', 'PCI', 'Cell Identity', 'eNB_ID', 'next_eNB_ID', 'Band ID', 'next_BID', 'DL frequency', 'UL frequency', 'DL bandwidth', 'UL bandwidth', 'TAC', 'MCC', 'MNC']\n",
    "        table = pd.DataFrame(columns=['type', 'start', 'end', 'others', 'm_src', 'm_tgt', 's_src', 's_tgt', 'category', 'inter-eNB', 'inter-gNB', 'inter-Freq', 'band_cng', 'inter-RAT', '4G_5G', 'cause', 'near_before_RLF', *selected_cols])\n",
    "        print('Handover Not Found!!!')\n",
    "        return table, new_D\n",
    "    \n",
    "    # add Cell Identity & eNB ID\n",
    "    sc_info = df[df['type_id'] == 'LTE_RRC_Serv_Cell_Info'][['Timestamp', 'type_id', 'PCI', 'Cell Identity', 'Band ID', 'DL frequency', 'UL frequency', 'DL bandwidth', 'UL bandwidth', 'TAC', 'MCC', 'MNC']].reset_index(drop=True).rename(columns={'Timestamp': 'start', 'type_id': 'type'})\n",
    "    sc_info['eNB_ID'] = sc_info['Cell Identity'] // 256\n",
    "    # sc_info['Cell_ID'] = sc_info['Cell Identity'] % 256\n",
    "    sc_info = sc_info[['start', 'type', 'PCI', 'Cell Identity', 'eNB_ID', 'Band ID', 'DL frequency', 'UL frequency', 'DL bandwidth', 'UL bandwidth', 'TAC', 'MCC', 'MNC']]\n",
    "\n",
    "    table = pd.concat([table, sc_info], ignore_index=True).sort_values(by='start').reset_index(drop=True)\n",
    "\n",
    "    is_not_start = True\n",
    "    selected_cols = ['PCI', 'Cell Identity', 'eNB_ID', 'Band ID', 'DL frequency', 'UL frequency', 'DL bandwidth', 'UL bandwidth', 'TAC', 'MCC', 'MNC']\n",
    "    for i, row in table.iterrows():\n",
    "        if row['type'] == 'LTE_RRC_Serv_Cell_Info':\n",
    "            is_not_start = False\n",
    "            info_to_fill = row[selected_cols].to_list()\n",
    "            continue\n",
    "        if is_not_start:\n",
    "            continue\n",
    "        table.loc[i, selected_cols] = info_to_fill\n",
    "\n",
    "    table = table[table['type'] != 'LTE_RRC_Serv_Cell_Info'].reset_index(drop=True)\n",
    "    \n",
    "    # parse source & target cells\n",
    "    for i, row in table.iterrows():\n",
    "        table.loc[i, ['m_src', 'm_tgt', 's_src', 's_tgt']] = parse_trans(row['trans'])\n",
    "    \n",
    "    # distinguish intra/inter-eNB HO\n",
    "    table1 = table[np.in1d(table['type'], ['SCLA', 'SCGA', 'SCGR-I', 'SCGF'])]\n",
    "    table = table[~np.in1d(table['type'], ['SCLA', 'SCGA', 'SCGR-I', 'SCGF'])].reset_index(drop=True)\n",
    "    \n",
    "    table['next_eNB'] = table['eNB_ID'].shift(-1)\n",
    "    for i, row in table.iloc[:-1].iterrows():\n",
    "        if row['eNB_ID'] != row['next_eNB'] and row['type'] not in ['CXNS', 'CXNR']:\n",
    "            if row['others'] == '':\n",
    "                table.at[i, 'others'] = 'Inter eNB HO.'\n",
    "            else:\n",
    "                table.at[i, 'others'] += ' Inter eNB HO.'\n",
    "    \n",
    "    table = pd.concat([table, table1], ignore_index=True).sort_values(by='start').reset_index(drop=True)\n",
    "    \n",
    "    # label SCG Addition near after SCG Failure\n",
    "    table1 = table[~np.in1d(table['type'], ['SCGA', 'SCGR-I', 'SCGR-II'])]\n",
    "    table = table[np.in1d(table['type'], ['SCGA', 'SCGR-I', 'SCGR-II'])].reset_index(drop=True)\n",
    "    \n",
    "    table['prev_cmt'] = table['others'].shift(1)\n",
    "    for i, row in table.iloc[1:].iterrows():\n",
    "        if row['type'] == 'SCGA':\n",
    "            if 'Near after SN_Rel' in row['others'] and 'Caused by scg-failure' in row['prev_cmt']:\n",
    "                table.at[i, 'others'] += ' Caused by scg-failure.'\n",
    "    \n",
    "    # with pd.option_context('display.max_rows', None): \n",
    "    #     display(table)\n",
    "    \n",
    "    # combine closed SCG Addition & Release pair (which are not caused by scg-failure or RLF) into SCG Change\n",
    "    table['next_end'] = table['end'].shift(-1)\n",
    "    table['next_cmt'] = table['others'].shift(-1)\n",
    "    table['next_s_tgt'] = table['s_tgt'].shift(-1)\n",
    "    indices_to_remove = []\n",
    "    for i, row in table.iloc[:-1].iterrows():\n",
    "        if row['type'] == 'SCGR-I' and 'Near after SN_Rel' in row['next_cmt'] and row['s_src'] != row['next_s_tgt']:\n",
    "            table.at[i, 'end'] = row['next_end']\n",
    "            table.at[i, 's_tgt'] = row['next_s_tgt']\n",
    "            table.at[i, 'type'] = 'SCGC-I'\n",
    "            indices_to_remove.append(i+1)\n",
    "        if row['type'] == 'SCGR-II' and 'Near after MN_HO_to_eNB' in row['next_cmt'] and row['s_src'] != row['next_s_tgt']:\n",
    "            table.at[i, 'end'] = row['next_end']\n",
    "            table.at[i, 's_tgt'] = row['next_s_tgt']\n",
    "            table.at[i, 'type'] = 'SCGC-II'\n",
    "            indices_to_remove.append(i+1)\n",
    "    table = table.drop(indices_to_remove)\n",
    "    \n",
    "    # with pd.option_context('display.max_rows', None): \n",
    "    #     display(table)\n",
    "    \n",
    "    table = pd.concat([table, table1], ignore_index=True).sort_values(by='start').reset_index(drop=True)\n",
    "    \n",
    "    # re-classify eNB HO & MeNB HO\n",
    "    table.loc[np.in1d(table['type'], ['LTEH']) & table['others'].str.contains('Inter eNB HO'), 'type'] = 'ENBH'\n",
    "    table.loc[np.in1d(table['type'], ['MCGH']) & table['others'].str.contains('Inter eNB HO'), 'type'] = 'MNBH'\n",
    "    \n",
    "    # add the next eNB ID when meeting inter-eNB HO\n",
    "    table1 = table[~table['others'].str.contains('Inter eNB HO')]\n",
    "    table = table[table['others'].str.contains('Inter eNB HO')].reset_index(drop=True)\n",
    "    \n",
    "    table['next_eNB_ID'] = table['eNB_ID'].shift(-1)\n",
    "    \n",
    "    table = pd.concat([table, table1], ignore_index=True).sort_values(by='start').reset_index(drop=True)\n",
    "    \n",
    "    # detect band change and add the next Band ID when meeting inter-Freq HO\n",
    "    band_mapping = {}\n",
    "    for i, row in table[~table.duplicated(subset=['DL frequency'])].dropna(subset=['DL frequency']).iterrows():\n",
    "        band_mapping[int(row['DL frequency'])] = row['Band ID']\n",
    "    \n",
    "    print(band_mapping)\n",
    "    \n",
    "    table1 = table[~table['others'].str.contains('Inter frequency HO')]\n",
    "    table = table[table['others'].str.contains('Inter frequency HO')].reset_index(drop=True)\n",
    "    \n",
    "    table['next_BID'] = table['Band ID'].shift(-1)\n",
    "    try:\n",
    "        table.at[len(table)-1, 'next_BID'] = band_mapping[ast.literal_eval(table.iloc[-1]['m_tgt'])[1]]\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    table = pd.concat([table, table1], ignore_index=True).sort_values(by='start').reset_index(drop=True)\n",
    "    \n",
    "    # check whether RLF is near after an HO event\n",
    "    table1 = table[np.in1d(table['type'], ['CXNS', 'CXNR', 'SCLA'])]\n",
    "    table = table[~np.in1d(table['type'], ['CXNS', 'CXNR', 'SCLA'])].reset_index(drop=True)\n",
    "    \n",
    "    table['next_start'] = table['start'].shift(-1)\n",
    "    table['next_type'] = table['type'].shift(-1)\n",
    "    table['near_before_RLF'] = False\n",
    "    for i, row in table.iloc[:-1].iterrows():\n",
    "        # check whether an HO event is near before an RLF (in 3 seconds)\n",
    "        if row['type'] in ['LTEH', 'ENBH', 'MCGH', 'MNBH', 'SCGM', 'SCGA', 'SCGR-I', 'SCGR-II', 'SCGC-I', 'SCGC-II'] and \\\n",
    "            row['next_type'] in ['NASR', 'MCGF', 'SCGF']:\n",
    "                if row['end'] > row['next_start'] - pd.Timedelta(seconds=1):\n",
    "                    table.at[i, 'near_before_RLF'] = True\n",
    "                    next_type = row['next_type']\n",
    "                    if row['others'] == '':\n",
    "                        table.at[i, 'others'] = f'Near before {next_type} 1 sec.'\n",
    "                    else:\n",
    "                        table.at[i, 'others'] += f' Near before {next_type} 1 sec.'\n",
    "                        \n",
    "                elif row['end'] > row['next_start'] - pd.Timedelta(seconds=2):\n",
    "                    table.at[i, 'near_before_RLF'] = True\n",
    "                    next_type = row['next_type']\n",
    "                    if row['others'] == '':\n",
    "                        table.at[i, 'others'] = f'Near before {next_type} 2 sec.'\n",
    "                    else:\n",
    "                        table.at[i, 'others'] += f' Near before {next_type} 2 sec.'\n",
    "                        \n",
    "                elif row['end'] > row['next_start'] - pd.Timedelta(seconds=3):\n",
    "                    table.at[i, 'near_before_RLF'] = True\n",
    "                    next_type = row['next_type']\n",
    "                    if row['others'] == '':\n",
    "                        table.at[i, 'others'] = f'Near before {next_type} 3 sec.'\n",
    "                    else:\n",
    "                        table.at[i, 'others'] += f' Near before {next_type} 3 sec.'\n",
    "                    \n",
    "    table = pd.concat([table, table1], ignore_index=True).sort_values(by='start').reset_index(drop=True)\n",
    "    \n",
    "    # label (PCI, BSID)\n",
    "    table1 = table[np.in1d(table['type'], ['CXNS', 'CXNR', 'SCLA'])]\n",
    "    table = table[~np.in1d(table['type'], ['CXNS', 'CXNR', 'SCLA'])].reset_index(drop=True)\n",
    "    \n",
    "    for col in ['m_src', 's_src']:\n",
    "        new_col = f'{col}1'\n",
    "        filtered_table = table[table[col].isna()].copy()\n",
    "        filtered_table[new_col] = np.nan\n",
    "        \n",
    "        # add BSID (eNB)\n",
    "        filtered_table1 = table[table[col].notna()].copy()\n",
    "        filtered_table1[new_col] = filtered_table1['m_src'].astype(str) + ', ' + filtered_table1['eNB_ID'].astype(str)\n",
    "        \n",
    "        table = pd.concat([filtered_table, filtered_table1], ignore_index=True).sort_values(by='start').reset_index(drop=True)\n",
    "    \n",
    "    for col in ['m_tgt', 's_tgt']:\n",
    "        new_col = f'{col}1'\n",
    "        filtered_table = table[table[col].isna()].copy()\n",
    "        filtered_table[new_col] = np.nan\n",
    "        \n",
    "        # add BSID (eNB)\n",
    "        filtered_table1 = table[table[col].notna() & table['next_eNB_ID'].notna()].copy()\n",
    "        filtered_table1[new_col] = filtered_table1['m_src'].astype(str) + ', ' + filtered_table1['next_eNB_ID'].astype(str)\n",
    "        filtered_table2 = table[table[col].notna() & table['next_eNB_ID'].isna()].copy()\n",
    "        filtered_table2[new_col] = filtered_table2['m_src'].astype(str) + ', ' + filtered_table2['eNB_ID'].astype(str)\n",
    "        \n",
    "        table = pd.concat([filtered_table, filtered_table1, filtered_table2], ignore_index=True).sort_values(by='start').reset_index(drop=True)\n",
    "    \n",
    "    table = pd.concat([table, table1], ignore_index=True).sort_values(by='start').reset_index(drop=True)\n",
    "    \n",
    "    # add category\n",
    "    table['category'] = 'Others'\n",
    "    table.loc[np.in1d(table['type'], ['LTEH', 'ENBH', 'MCGH', 'MNBH', 'SCGM', 'SCGA', 'SCGR-I', 'SCGC-I', 'SCGR-II', 'SCGC-II']), 'category'] = 'HO'\n",
    "    table.loc[np.in1d(table['type'], ['MCGF', 'NASR', 'SCGF']), 'category'] = 'RLF'\n",
    "\n",
    "    # add failure cause\n",
    "    failure_cause = [\n",
    "        'reconfigurationFailure (0)', 'handoverFailure (1)', 'otherFailure (2)',\n",
    "        't310-Expiry (0)', 'randomAccessProblem (1)', 'rlc-MaxNumRetx (2)', 'synchReconfigFailureSCG (3)', 'scg-ReconfigFailure (4)', 'srb3-IntegrityFailure (5)', 'other-r16 (6)'\n",
    "    ]\n",
    "    \n",
    "    for tag in failure_cause:\n",
    "        table.loc[table['others'].str.contains(tag, regex=False), 'cause'] = tag\n",
    "        table['others'] = table['others'].str.replace(f\" {tag}.\", \"\", regex=False)\n",
    "        table['others'] = table['others'].str.replace(f\"{tag}.\", \"\", regex=False)\n",
    "    \n",
    "    # add Access Technology type\n",
    "    table['4G_5G'] = '4G'\n",
    "    table.loc[np.in1d(table['type'], ['SCGM', 'SCGA', 'SCGR-I', 'SCGC-I', 'SCGF']), '4G_5G'] = '5G'\n",
    "    table.loc[np.in1d(table['type'], ['SCGR-II', 'SCGC-II']), '4G_5G'] = '4G_5G'\n",
    "    \n",
    "    # add more boolean columns\n",
    "    table['inter-eNB'] = False\n",
    "    table.loc[table['others'].str.contains('Inter eNB HO'), 'inter-eNB'] = True\n",
    "    table['others'] = table['others'].str.replace(\" Inter eNB HO.\", \"\")\n",
    "    table['others'] = table['others'].str.replace(\"Inter eNB HO.\", \"\")\n",
    "    \n",
    "    table['inter-Freq'] = False\n",
    "    table.loc[table['others'].str.contains('Inter frequency HO'), 'inter-Freq'] = True\n",
    "    table['others'] = table['others'].str.replace(\" Inter frequency HO.\", \"\")\n",
    "    table['others'] = table['others'].str.replace(\"Inter frequency HO.\", \"\")\n",
    "    \n",
    "    table['band_cng'] = False\n",
    "    table.loc[table['inter-Freq'] & (table['Band ID'] != table['next_BID']), 'band_cng'] = True\n",
    "    \n",
    "    table['inter-RAT'] = False\n",
    "    table.loc[np.in1d(table['type'], ['SCGA', 'SCGR-I', 'SCGC-I', 'SCGR-II', 'SCGC-II']), 'inter-RAT'] = True\n",
    "    \n",
    "    table['inter-gNB'] = False\n",
    "    table.loc[np.in1d(table['type'], ['SCGC-I', 'SCGC-II']), 'inter-gNB'] = True\n",
    "    \n",
    "    # find row na-\"end\" & fill with \"start\"\n",
    "    if endfill:\n",
    "        nan_end_rows = table[table['end'].isnull()]\n",
    "        table.loc[nan_end_rows.index, 'end'] = nan_end_rows['start']\n",
    "    \n",
    "    # ignore CXNS, CXNR, SCLA\n",
    "    table = table[~np.in1d(table['type'], ['CXNS', 'CXNR', 'SCLA'])].reset_index(drop=True)\n",
    "    \n",
    "    # remove SCG Addition, Release caused by SCG Failure or any other RLFs if needed (default: True)\n",
    "    if radical:\n",
    "        table = table[~((table['others'].str.contains('Caused by scg-failure') | table['others'].str.contains('Near after RLF')))].reset_index(drop=True)\n",
    "    \n",
    "    # select columns\n",
    "    selected_cols = ['m_src1', 'm_tgt1', 's_src1', 's_tgt1', 'PCI', 'Cell Identity', 'eNB_ID', 'next_eNB_ID', 'Band ID', 'next_BID', 'DL frequency', 'UL frequency', 'DL bandwidth', 'UL bandwidth', 'TAC', 'MCC', 'MNC']\n",
    "    table = table[['type', 'start', 'end', 'others', 'm_src', 'm_tgt', 's_src', 's_tgt', 'category', 'inter-eNB', 'inter-gNB', 'inter-Freq', 'band_cng', 'inter-RAT', '4G_5G', 'cause', 'near_before_RLF', *selected_cols]]\n",
    "    \n",
    "    return table, new_D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ************************************************* label ho *************************************************\n",
    "\n",
    "def handover_classify_labelling(df_ho, df_dl=None, df_ul=None, ratio=0.5, scope=None):\n",
    "    \n",
    "    if scope is None:\n",
    "        scope = {\n",
    "            'LTEH': (-4.0, 2.0, 0.018),\n",
    "            'ENBH': (-4.0, 2.6, 0.019),\n",
    "            'MCGH': (-3.0, 3.3, 0.019),\n",
    "            'MNBH': (-3.2, 3.3, 0.02),\n",
    "            'SCGM': (-4.2, 3.3, 0.017),\n",
    "            'SCGA': (-1.2, 2.6, 0.027),\n",
    "            'SCGR-I': (-3.1, 3.3, 0.04),\n",
    "            'SCGC-I': (-3.0, 2.9, 0.37),\n",
    "            'SCGR-II': (-2.0, 4.1, 0.034),\n",
    "            'SCGC-II': (-2.0, 3.2, 0.396),\n",
    "            'MCGF': (-5.8, 7.2, 0.078),\n",
    "            'NASR': (-4.0, 6.5, 0.394),\n",
    "            'SCGF': (-4.0, 4.6, 0.111)\n",
    "        }\n",
    "        \n",
    "    def interp(x, y, ratio):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x, y (datetime.datetime): x < y\n",
    "            ratio (float): a decimal numeral in a range [0, 1]; 0 means break at x, 1 means break at y.\n",
    "        Returns:\n",
    "            (datetime.datetime): breakpoint of interpolation\n",
    "        \"\"\"\n",
    "        return x + (y - x) * ratio\n",
    "\n",
    "    Metrics = namedtuple('Metrics', ['dl_pkt', 'dl_lost', 'dl_excl', 'ul_pkt', 'ul_lost', 'ul_excl'])\n",
    "    Duration = namedtuple('Duration', ['total', 'stable', 'unstable'])\n",
    "\n",
    "    mcgf = [f'MCGF_{suffix}' for suffix in ['reconfigurationFailure (0)', 'handoverFailure (1)', 'otherFailure (2)']]\n",
    "    nasr = [f'NASR_{suffix}' for suffix in ['reconfigurationFailure (0)', 'handoverFailure (1)', 'otherFailure (2)']]\n",
    "    scgf = [f'SCGF_{suffix}' for suffix in ['t310-Expiry (0)', 'randomAccessProblem (1)', 'rlc-MaxNumRetx (2)', 'synchReconfigFailureSCG (3)', 'scg-ReconfigFailure (4)', 'srb3-IntegrityFailure (5)', 'other-r16 (6)']]\n",
    "\n",
    "    E = { stage: { key: [] for key in [*scope.keys(), *mcgf, *nasr, *scgf] } for stage in ['before', 'during', 'after']}\n",
    "    E['overview'] = {}\n",
    "\n",
    "    selected_cols = ['stage', 'category', 'type', 'cause', 'index', 'inter-RAT', 'inter-eNB', 'inter-gNB', 'inter-Freq', 'band_cng']\n",
    "    reset_values = ['-', 'stable', 'stable', '-', -1, False, False, False, False, False]\n",
    "    \n",
    "    dl_start_time, dl_end_time = pd.Timestamp.max, pd.Timestamp.min\n",
    "    if df_dl is not None:\n",
    "        dl_start_time, dl_end_time = df_dl.iloc[0]['Timestamp'] - pd.Timedelta(seconds=0.1), df_dl.iloc[-1]['Timestamp'] + pd.Timedelta(seconds=0.1)\n",
    "        # df_dl = df_dl.reindex(columns=[*list(df_dl.columns), *selected_cols])\n",
    "        # Reset the specified columns using a loop\n",
    "        for col, reset_value in zip(selected_cols, reset_values):\n",
    "            df_dl[col] = reset_value\n",
    "    \n",
    "    ul_start_time, ul_end_time = pd.Timestamp.max, pd.Timestamp.min\n",
    "    if df_ul is not None:\n",
    "        ul_start_time, ul_end_time = df_ul.iloc[0]['Timestamp'] - pd.Timedelta(seconds=0.1), df_ul.iloc[-1]['Timestamp'] + pd.Timedelta(seconds=0.1)\n",
    "        # df_ul = df_ul.reindex(columns=[*list(df_ul.columns), *selected_cols])\n",
    "        # Reset the specified columns using a loop\n",
    "        for col, reset_value in zip(selected_cols, reset_values):\n",
    "            df_ul[col] = reset_value\n",
    "            \n",
    "    start_time, end_time = min(dl_start_time, ul_start_time), max(dl_end_time, ul_end_time)\n",
    "    stable_interval = P.open(start_time, end_time)\n",
    "    for i, row in df_ho.iterrows():\n",
    "        prior_row = df_ho.iloc[i-1] if i != 0 else None\n",
    "        post_row = df_ho.iloc[i+1] if i != len(df_ho) - 1 else None\n",
    "        \n",
    "        # Peek the next event to avoid HO overlapping with handoverFailure (skip and set the next prior event)\n",
    "        if i != len(df_ho) - 1 and pd.notna(row.end) and row.end > post_row.start:\n",
    "            print('Overlapping event occurs!!')\n",
    "            print(i, row['start'], row['end'], row['type'], row['cause'])\n",
    "            print(i+1, post_row['start'], post_row['end'], post_row['type'], post_row['cause'])\n",
    "            continue\n",
    "        if i != 0 and pd.notna(prior_row.end) and prior_row.end > row.start:\n",
    "            prior_row = df_ho.iloc[i-2] if i > 1 else None\n",
    "        \n",
    "        # Basic information\n",
    "        tag = row['type']  # specific column name\n",
    "        cause = row['cause']\n",
    "        start, end = row['start'], row['end']  # handover start/end time\n",
    "        intr = (end - start).total_seconds() if pd.notna(end) else 0  # handover interruption time\n",
    "        ho_info = [row['category'], row['type'], row['cause'], i, row['inter-RAT'], row['inter-eNB'], row['inter-gNB'], row['inter-Freq'], row['band_cng']]\n",
    "        \n",
    "        # peri_interval\n",
    "        if pd.isna(row.end):\n",
    "            peri_interval = P.singleton(row.start)\n",
    "        else:\n",
    "            peri_interval = P.closed(row.start, row.end)\n",
    "\n",
    "        # prior_interval\n",
    "        C = row.start + pd.Timedelta(seconds=scope[tag][0])\n",
    "        D = row.start\n",
    "        prior_interval = P.closedopen(C, D)\n",
    "        if ratio is not None and i != 0:\n",
    "            prior_tag = prior_row['type']\n",
    "            A = max(prior_row.start, prior_row.end)\n",
    "            B = max(prior_row.start, prior_row.end) + pd.Timedelta(seconds=scope[prior_tag][1]-scope[prior_tag][2])\n",
    "            if P.openclosed(A, B).overlaps(prior_interval):\n",
    "                # print(\"Overlaps with the previous!\")\n",
    "                bkp = interp(C, B, ratio)\n",
    "                bkp = max(bkp, A)  # avoid the breakpoint overlapping the previous event's duration\n",
    "                # bkp = min(max(bkp, A), D)  # 我不侵犯到其他任何人，代表其他人也不會侵犯到我！可不加！\n",
    "                prior_interval = P.closedopen(bkp, D)\n",
    "                if A in prior_interval:\n",
    "                    prior_interval = P.open(bkp, D)\n",
    "        \n",
    "        # post_interval\n",
    "        C = row.end\n",
    "        D = row.end + pd.Timedelta(seconds=scope[tag][1]-scope[tag][2])\n",
    "        post_interval = P.openclosed(C, D)\n",
    "        if ratio is not None and i != len(df_ho)-1:\n",
    "            post_tag = post_row['type']\n",
    "            A = min(post_row.start, post_row.end) + pd.Timedelta(seconds=scope[post_tag][0])\n",
    "            B = min(post_row.start, post_row.end)\n",
    "            if P.closedopen(A, B).overlaps(post_interval):\n",
    "                # print(\"Overlaps with the following!\")\n",
    "                bkp = interp(A, D, ratio)\n",
    "                bkp = min(bkp, B)  # avoid the breakpoint overlappint the following event's duration\n",
    "                # bkp = max(min(bkp, B), C)  # 我不侵犯到其他任何人，代表其他人也不會侵犯到我！可不加！\n",
    "                post_interval = P.open(C, bkp)\n",
    "        \n",
    "        # calculate lost & excl\n",
    "        dl_pkt, dl_lost, dl_excl = [0, 0, 0], [0, 0, 0], [0, 0, 0]\n",
    "        if df_dl is not None:\n",
    "            for i, (stage, intv) in enumerate(zip(['before', 'during', 'after'], [prior_interval, peri_interval, post_interval])):\n",
    "                if intv.empty:\n",
    "                    continue\n",
    "                filt = (df_dl['arr_time'] >= intv.lower) & (df_dl['arr_time'] < intv.upper)\n",
    "                tmp = df_dl[filt].copy()\n",
    "                dl_pkt[i] = len(tmp)\n",
    "                dl_lost[i] = sum(tmp['lost'])\n",
    "                dl_excl[i] = sum(~tmp['lost'] & tmp['excl'])\n",
    "                df_dl.loc[filt, selected_cols] = [stage, *ho_info]\n",
    "        \n",
    "        ul_pkt, ul_lost, ul_excl = [0, 0, 0], [0, 0, 0], [0, 0, 0]\n",
    "        if df_ul is not None:\n",
    "            for i, (stage, intv) in enumerate(zip(['before', 'during', 'after'], [prior_interval, peri_interval, post_interval])):\n",
    "                if intv.empty:\n",
    "                    continue\n",
    "                filt = (df_ul['xmit_time'] >= intv.lower) & (df_ul['xmit_time'] < intv.upper)\n",
    "                tmp = df_ul[filt].copy()\n",
    "                ul_pkt[i] = len(tmp)\n",
    "                ul_lost[i] = sum(tmp['lost'])\n",
    "                ul_excl[i] = sum(~tmp['lost'] & tmp['excl'])\n",
    "                df_ul.loc[filt, selected_cols] = [stage, *ho_info]\n",
    "        \n",
    "        # fill in the blank\n",
    "        for i, (stage, intv) in enumerate(zip(['before', 'during', 'after'], [prior_interval, peri_interval, post_interval])):\n",
    "            E[stage][tag].append((intv, Metrics(dl_pkt[i], dl_lost[i], dl_excl[i], ul_pkt[i], ul_lost[i], ul_excl[i])))\n",
    "            if tag in ['MCGF', 'NASR', 'SCGF']:\n",
    "                E[stage][f'{tag}_{cause}'].append((intv, Metrics(dl_pkt[i], dl_lost[i], dl_excl[i], ul_pkt[i], ul_lost[i], ul_excl[i])))\n",
    "        \n",
    "        # update stable interval\n",
    "        stable_interval = stable_interval - prior_interval - peri_interval - post_interval\n",
    "    \n",
    "    stable_dl_pkt, stable_dl_lost, stable_dl_excl = 0, 0, 0\n",
    "    stable_ul_pkt, stable_ul_lost, stable_ul_excl = 0, 0, 0\n",
    "    if df_dl is not None:\n",
    "        tmp = df_dl[df_dl['category'] == 'stable'].copy()\n",
    "        stable_dl_pkt = len(tmp)\n",
    "        stable_dl_lost = sum(tmp['lost'])\n",
    "        stable_dl_excl = sum(~tmp['lost'] & tmp['excl'])\n",
    "    \n",
    "    if df_ul is not None:\n",
    "        tmp = df_ul[df_ul['category'] == 'stable'].copy()\n",
    "        stable_ul_pkt = len(tmp)\n",
    "        stable_ul_lost = sum(tmp['lost'])\n",
    "        stable_ul_excl = sum(~tmp['lost'] & tmp['excl'])\n",
    "    \n",
    "    total_duration = (end_time - start_time).total_seconds()\n",
    "    stable_duration = 0\n",
    "    for intv in stable_interval:\n",
    "        if intv.empty:\n",
    "            continue\n",
    "        stable_duration += (intv.upper - intv.lower).total_seconds()\n",
    "    unstable_duration = total_duration - stable_duration\n",
    "    \n",
    "    E['overview']['stable_intv'] = (stable_interval, Metrics(stable_dl_pkt, stable_dl_lost, stable_dl_excl, stable_ul_pkt, stable_ul_lost, stable_ul_excl))\n",
    "    E['overview']['duration'] = Duration(total_duration, stable_duration, unstable_duration)\n",
    "\n",
    "    return E, df_dl, df_ul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics_duration_into_dict(E):\n",
    "    mcgf = [f'MCGF_{suffix}' for suffix in ['reconfigurationFailure (0)', 'handoverFailure (1)', 'otherFailure (2)']]\n",
    "    nasr = [f'NASR_{suffix}' for suffix in ['reconfigurationFailure (0)', 'handoverFailure (1)', 'otherFailure (2)']]\n",
    "    scgf = [f'SCGF_{suffix}' for suffix in ['t310-Expiry (0)', 'randomAccessProblem (1)', 'rlc-MaxNumRetx (2)', 'synchReconfigFailureSCG (3)', 'scg-ReconfigFailure (4)', 'srb3-IntegrityFailure (5)', 'other-r16 (6)']]\n",
    "\n",
    "    A = { stage: { key: [] for key in ['LTEH', 'ENBH', 'MCGH', 'MNBH', 'SCGM', 'SCGA', 'SCGR-I', 'SCGC-I', 'SCGR-II', 'SCGC-II',\n",
    "                                    'MCGF', 'NASR', 'SCGF', *mcgf, *nasr, *scgf] } for stage in ['before', 'during', 'after'] }\n",
    "    A['overview'] = {}\n",
    "\n",
    "    for stage in ['before', 'during', 'after']:\n",
    "        for tag, lst in E[stage].items():\n",
    "            for item in lst:\n",
    "                A[stage][tag].append((item[0], item[1]._asdict()))\n",
    "    A['overview']['stable_intv'] = (E['overview']['stable_intv'][0], E['overview']['stable_intv'][1]._asdict())\n",
    "    A['overview']['duration'] = E['overview']['duration']._asdict()\n",
    "    \n",
    "    return A\n",
    "\n",
    "def dict_into_metrics_duration(A):\n",
    "    Metrics = namedtuple('Metrics', ['dl_pkt', 'dl_lost', 'dl_excl', 'ul_pkt', 'ul_lost', 'ul_excl'])\n",
    "    Duration = namedtuple('Duration', ['total', 'stable', 'unstable'])\n",
    "\n",
    "    mcgf = [f'MCGF_{suffix}' for suffix in ['reconfigurationFailure (0)', 'handoverFailure (1)', 'otherFailure (2)']]\n",
    "    nasr = [f'NASR_{suffix}' for suffix in ['reconfigurationFailure (0)', 'handoverFailure (1)', 'otherFailure (2)']]\n",
    "    scgf = [f'SCGF_{suffix}' for suffix in ['t310-Expiry (0)', 'randomAccessProblem (1)', 'rlc-MaxNumRetx (2)', 'synchReconfigFailureSCG (3)', 'scg-ReconfigFailure (4)', 'srb3-IntegrityFailure (5)', 'other-r16 (6)']]\n",
    "\n",
    "    B = { stage: { key: [] for key in ['LTEH', 'ENBH', 'MCGH', 'MNBH', 'SCGM', 'SCGA', 'SCGR-I', 'SCGC-I', 'SCGR-II', 'SCGC-II',\n",
    "                                    'MCGF', 'NASR', 'SCGF', *mcgf, *nasr, *scgf] } for stage in ['before', 'during', 'after'] }\n",
    "    B['overview'] = {}\n",
    "\n",
    "    for stage in ['before', 'during', 'after']:\n",
    "        for tag, lst in A[stage].items():\n",
    "            for item in lst:\n",
    "                B[stage][tag].append((item[0], Metrics(**item[1])))\n",
    "    B['overview']['stable_intv'] = (A['overview']['stable_intv'][0], Metrics(**A['overview']['stable_intv'][1]))\n",
    "    B['overview']['duration'] = Duration(**A['overview']['duration'])\n",
    "    \n",
    "    return B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-16 1\n",
      "{'UDP_Bandlock_B1_B7_B8_RM500Q': {'route': 'BR', 'devices': {'qc00': 'B1', 'qc02': 'B7', 'qc03': 'B8'}, 'ods': [[0, 'Origin Station', 'Destination Station', 'Departure Time', 'Notes'], [1, '萬芳醫院', '動物園', '19:23', ''], [2, '動物園', '萬芳醫院', '19:32', ''], [3, '萬芳醫院', '動物園', '19:39', ''], [4, '動物園', '萬芳醫院', '19:47', ''], [5, '萬芳醫院', '動物園', '19:55', ''], [6, '動物園', '萬芳醫院', '20:03', ''], [7, '萬芳醫院', '動物園', '20:09', ''], [8, '動物園', '萬芳醫院', '20:18', ''], [9, '萬芳醫院', '動物園', '20:27', ''], [10, '動物園', '萬芳醫院', '20:33', ''], [11, '萬芳醫院', '動物園', '20:42', ''], [12, '動物園', '萬芳醫院', '20:49', '']], 'stations': ['動物園', '木柵', '萬芳社區', '萬芳醫院'], 'telecom': 'CHT', 'protocol': 'UDP', 'length': [250, 'byte'], 'bitrate': [1, 'Mbps'], 'notes': ''}}\n",
      "2023-03-26 1\n",
      "{'UDP_Bandlock_All_RM500Q': {'route': 'BR', 'devices': {'qc00': 'All', 'qc02': 'All', 'qc03': 'All'}, 'ods': [[0, 'Origin Station', 'Destination Station', 'Departure Time', 'Notes'], [1, '萬芳醫院', '動物園', '16:36', ''], [2, '動物園', '萬芳醫院', '16:46', ''], [3, '萬芳醫院', '動物園', '16:56', ''], [4, '動物園', '萬芳醫院', '17:25', '']], 'stations': ['動物園', '木柵', '萬芳社區', '萬芳醫院'], 'telecom': 'CHT', 'protocol': 'UDP', 'length': [250, 'byte'], 'bitrate': [1, 'Mbps'], 'notes': ''}}\n",
      "2023-04-01 2\n",
      "{'UDP_Bandlock_B1_B3_B7_B8_RM500Q': {'route': 'BR', 'devices': {'qc00': 'B1', 'qc01': 'B3', 'qc02': 'B7', 'qc03': 'B8'}, 'ods': [[0, 'Origin Station', 'Destination Station', 'Departure Time', 'Notes'], [1, '萬芳醫院', '動物園', '14:07', ''], [2, '動物園', '萬芳醫院', '14:21', ''], [3, '萬芳醫院', '動物園', '14:32', ''], [4, '動物園', '萬芳醫院', '14:45', ''], [5, '萬芳醫院', '動物園', '14:56', ''], [6, '動物園', '萬芳醫院', '15:06', '']], 'stations': ['動物園', '木柵', '萬芳社區', '萬芳醫院'], 'telecom': 'CHT', 'protocol': 'UDP', 'length': [250, 'byte'], 'bitrate': [1, 'Mbps'], 'notes': ''}}\n",
      "{'UDP_Bandlock_B1B3_B1B8_LTE_All_RM500Q': {'route': 'BR', 'devices': {'qc00': 'B1B3', 'qc01': 'B1B8', 'qc02': 'LTE', 'qc03': 'All'}, 'ods': [[0, 'Origin Station', 'Destination Station', 'Departure Time', 'Notes'], [1, '萬芳醫院', '動物園', '15:21', ''], [2, '動物園', '萬芳醫院', '15:30', ''], [3, '萬芳醫院', '動物園', '15:37', ''], [4, '動物園', '萬芳醫院', '15:51', '']], 'stations': ['動物園', '木柵', '萬芳社區', '萬芳醫院'], 'telecom': 'CHT', 'protocol': 'UDP', 'length': [250, 'byte'], 'bitrate': [1, 'Mbps'], 'notes': ''}}\n",
      "2023-04-10 3\n",
      "{'UDP_Bandlock_All_RM500Q': {'route': 'BR', 'devices': {'qc00': 'All', 'qc01': 'All', 'qc02': 'All', 'qc03': 'All'}, 'ods': [[0, 'Origin Station', 'Destination Station', 'Departure Time', 'Notes'], [1, '萬芳醫院', '動物園', '15:05', ''], [2, '動物園', '萬芳醫院', '15:19', '']], 'stations': ['動物園', '木柵', '萬芳社區', '萬芳醫院'], 'telecom': 'CHT', 'protocol': 'UDP', 'length': [250, 'byte'], 'bitrate': [1, 'Mbps'], 'notes': ''}}\n",
      "{'UDP_Bandlock_B1_B3_B7_B8_RM500Q': {'route': 'BR', 'devices': {'qc00': 'B1', 'qc01': 'B3', 'qc02': 'B7', 'qc03': 'B8'}, 'ods': [[0, 'Origin Station', 'Destination Station', 'Departure Time', 'Notes'], [1, '萬芳醫院', '動物園', '15:45', ''], [2, '動物園', '萬芳醫院', '16:07', '']], 'stations': ['動物園', '木柵', '萬芳社區', '萬芳醫院'], 'telecom': 'CHT', 'protocol': 'UDP', 'length': [250, 'byte'], 'bitrate': [1, 'Mbps'], 'notes': ''}}\n",
      "{'UDP_Bandlock_LTE_All_B7B8_B7_RM500Q': {'route': 'BR', 'devices': {'qc00': 'LTE', 'qc01': 'All', 'qc02': 'B7B7', 'qc03': 'B7'}, 'ods': [[0, 'Origin Station', 'Destination Station', 'Departure Time', 'Notes'], [1, '萬芳醫院', '動物園', '16:29', ''], [2, '動物園', '萬芳醫院', '16:42', '']], 'stations': ['動物園', '木柵', '萬芳社區', '萬芳醫院'], 'telecom': 'CHT', 'protocol': 'UDP', 'length': [250, 'byte'], 'bitrate': [1, 'Mbps'], 'notes': ''}}\n",
      "2023-04-17 6\n",
      "{'UDP_Bandlock_All_LTE_B1B3_B3B7_RM500Q': {'route': 'BR', 'devices': {'qc00': 'All', 'qc01': 'LTE', 'qc02': 'B1B3', 'qc03': 'B3B7'}, 'ods': [[0, 'Origin Station', 'Destination Station', 'Departure Time', 'Notes'], [1, '萬芳醫院', '動物園', '14:16', ''], [2, '動物園', '萬芳醫院', '14:23', ''], [3, '萬芳醫院', '動物園', '14:36', 'qc03 mi2log too small'], [4, '動物園', '萬芳醫院', '14:44', 'qc03 mi2log too small']], 'stations': ['動物園', '木柵', '萬芳社區', '萬芳醫院'], 'telecom': 'CHT', 'protocol': 'UDP', 'length': [250, 'byte'], 'bitrate': [1, 'Mbps'], 'notes': ''}}\n",
      "{'UDP_Bandlock_All_LTE_B1B7_B7B8_RM500Q': {'route': 'BR', 'devices': {'qc00': 'All', 'qc01': 'LTE', 'qc02': 'B1B7', 'qc03': 'B7B8'}, 'ods': [[0, 'Origin Station', 'Destination Station', 'Departure Time', 'Notes'], [1, '萬芳醫院', '動物園', '14:56', ''], [2, '動物園', '萬芳醫院', '15:03', ''], [3, '萬芳醫院', '動物園', '15:10', ''], [4, '動物園', '萬芳醫院', '15:19', '']], 'stations': ['動物園', '木柵', '萬芳社區', '萬芳醫院'], 'telecom': 'CHT', 'protocol': 'UDP', 'length': [250, 'byte'], 'bitrate': [1, 'Mbps'], 'notes': ''}}\n",
      "{'UDP_Bandlock_All_LTE_B1B8_B3B8_RM500Q': {'route': 'BR', 'devices': {'qc00': 'All', 'qc01': 'LTE', 'qc02': 'B1B8', 'qc03': 'B3B8'}, 'ods': [[0, 'Origin Station', 'Destination Station', 'Departure Time', 'Notes'], [1, '萬芳醫院', '動物園', '15:25', ''], [2, '動物園', '萬芳醫院', '15:34', ''], [3, '萬芳醫院', '動物園', '15:41', ''], [4, '動物園', '萬芳醫院', '15:49', '']], 'stations': ['動物園', '木柵', '萬芳社區', '萬芳醫院'], 'telecom': 'CHT', 'protocol': 'UDP', 'length': [250, 'byte'], 'bitrate': [1, 'Mbps'], 'notes': ''}}\n",
      "{'UDP_Bandlock_All_LTE_RM500Q': {'route': 'BR', 'devices': {'qc00': 'All', 'qc01': 'LTE', 'qc02': 'All', 'qc03': 'LTE'}, 'ods': [[0, 'Origin Station', 'Destination Station', 'Departure Time', 'Notes'], [1, '動物園', '萬芳醫院', '16:17', ''], [2, '動物園', '萬芳醫院', '16:36', ''], [3, '萬芳醫院', '動物園', '16:43', ''], [4, '動物園', '萬芳醫院', '16:51', '']], 'stations': ['動物園', '木柵', '萬芳社區', '萬芳醫院'], 'telecom': 'CHT', 'protocol': 'UDP', 'length': [250, 'byte'], 'bitrate': [1, 'Mbps'], 'notes': ''}}\n",
      "{'UDP_Bandlock_All_LTE_B1_B3_RM500Q': {'route': 'BR', 'devices': {'qc00': 'All', 'qc01': 'LTE', 'qc02': 'B1', 'qc03': 'B3'}, 'ods': [[0, 'Origin Station', 'Destination Station', 'Departure Time', 'Notes'], [1, '萬芳醫院', '動物園', '17:01', ''], [2, '動物園', '萬芳醫院', '17:09', '']], 'stations': ['動物園', '木柵', '萬芳社區', '萬芳醫院'], 'telecom': 'CHT', 'protocol': 'UDP', 'length': [250, 'byte'], 'bitrate': [1, 'Mbps'], 'notes': ''}}\n",
      "{'UDP_Bandlock_All_LTE_B7_B8_RM500Q': {'route': 'BR', 'devices': {'qc00': 'All', 'qc01': 'LTE', 'qc02': 'B7', 'qc03': 'B8'}, 'ods': [[0, 'Origin Station', 'Destination Station', 'Departure Time', 'Notes'], [1, '萬芳醫院', '動物園', '17:18', ''], [2, '動物園', '萬芳醫院', '17:27', '']], 'stations': ['動物園', '木柵', '萬芳社區', '萬芳醫院'], 'telecom': 'CHT', 'protocol': 'UDP', 'length': [250, 'byte'], 'bitrate': [1, 'Mbps'], 'notes': ''}}\n",
      "2023-05-04 1\n",
      "{'UDP_Bandlock_8S_Phone': {'route': 'BR', 'devices': {'sm00': 'All', 'sm01': 'B3', 'sm02': 'B7', 'sm03': 'B8', 'sm04': 'B3B7', 'sm05': 'B3B8', 'sm06': 'B7B8', 'sm07': 'LTE'}, 'ods': [[0, 'Origin Station', 'Destination Station', 'Departure Time', 'Notes'], [1, '萬芳醫院', '動物園', '13:54', ''], [2, '動物園', '萬芳醫院', '14:04', ''], [3, '萬芳醫院', '動物園', '14:14', ''], [4, '動物園', '萬芳醫院', '14:24', ''], [5, '萬芳醫院', '動物園', '14:31', ''], [6, '動物園', '萬芳醫院', '14:49', '']], 'stations': ['動物園', '木柵', '萬芳社區', '萬芳醫院'], 'telecom': 'CHT', 'protocol': 'UDP', 'length': [250, 'byte'], 'bitrate': [1, 'Mbps'], 'notes': ''}}\n",
      "2023-05-07 1\n",
      "{'UDP_Bandlock_8S_Phone': {'route': 'BR', 'devices': {'sm00': 'All', 'sm01': 'B3', 'sm02': 'B7', 'sm03': 'B8', 'sm04': 'B3B7', 'sm05': 'B3B8', 'sm06': 'B7B8', 'sm07': 'LTE'}, 'ods': [[0, 'Origin Station', 'Destination Station', 'Departure Time', 'Notes'], [1, '萬芳醫院', '動物園', '12:42', ''], [2, '動物園', '萬芳醫院', '12:51', ''], [3, '萬芳醫院', '動物園', '13:06', ''], [4, '動物園', '萬芳醫院', '13:15', ''], [5, '萬芳醫院', '動物園', '13:34', ''], [6, '動物園', '萬芳醫院', '13:44', ''], [7, '萬芳醫院', '動物園', '13:55', '']], 'stations': ['動物園', '木柵', '萬芳社區', '萬芳醫院'], 'telecom': 'CHT', 'protocol': 'UDP', 'length': [250, 'byte'], 'bitrate': [1, 'Mbps'], 'notes': ''}}\n",
      "2023-05-15 1\n",
      "{'UDP_Bandlock_8S_Phone': {'route': 'BR', 'devices': {'sm00': 'All', 'sm01': 'B3', 'sm02': 'B7', 'sm03': 'B8', 'sm04': 'B3B7', 'sm05': 'B3B8', 'sm06': 'B7B8', 'sm07': 'LTE'}, 'ods': [[0, 'Origin Station', 'Destination Station', 'Departure Time', 'Notes'], [1, '萬芳醫院', '動物園', '14:50', ''], [2, '動物園', '萬芳醫院', '15:19', ''], [3, '萬芳醫院', '動物園', '15:35', ''], [4, '動物園', '萬芳醫院', '15:54', '']], 'stations': ['動物園', '木柵', '萬芳社區', '萬芳醫院'], 'telecom': 'CHT', 'protocol': 'UDP', 'length': [250, 'byte'], 'bitrate': [1, 'Mbps'], 'notes': ''}}\n",
      "2023-05-24 1\n",
      "{'UDP_Bandlock_8S_Phone': {'route': 'BR', 'devices': {'sm00': 'All', 'sm01': 'B3', 'sm02': 'B7', 'sm03': 'B8', 'sm04': 'B3B7', 'sm05': 'B3B8', 'sm06': 'B7B8', 'sm07': 'LTE'}, 'ods': [[0, 'Origin Station', 'Destination Station', 'Departure Time', 'Notes'], [1, '萬芳醫院', '動物園', '14:26', ''], [2, '動物園', '萬芳醫院', '14:59', ''], [3, '萬芳醫院', '動物園', '15:10', ''], [4, '動物園', '萬芳醫院', '15:24', ''], [5, '萬芳醫院', '動物園', '15:35', ''], [6, '動物園', '萬芳醫院', '15:44', ''], [7, '萬芳醫院', '動物園', '15:55', ''], [8, '動物園', '萬芳醫院', '16:14', '']], 'stations': ['動物園', '木柵', '萬芳社區', '萬芳醫院'], 'telecom': 'CHT', 'protocol': 'UDP', 'length': [250, 'byte'], 'bitrate': [1, 'Mbps'], 'notes': ''}}\n",
      "2023-05-26 1\n",
      "{'UDP_Bandlock_8S_Phone': {'route': 'BR', 'devices': {'sm00': 'All', 'sm01': 'B3', 'sm02': 'B7', 'sm03': 'B8', 'sm04': 'B3B7', 'sm05': 'B3B8', 'sm06': 'B7B8', 'sm07': 'LTE'}, 'ods': [[0, 'Origin Station', 'Destination Station', 'Departure Time', 'Notes'], [1, '萬芳醫院', '動物園', '13;27', ''], [2, '動物園', '萬芳醫院', '13:36', ''], [3, '萬芳醫院', '動物園', '13:51', ''], [4, '動物園', '萬芳醫院', '14:01', ''], [5, '萬芳醫院', '動物園', '14:15', ''], [6, '動物園', '萬芳醫院', '14:31', ''], [7, '萬芳醫院', '動物園', '14:55', ''], [8, '動物園', '萬芳醫院', '15:06', ''], [9, '萬芳醫院', '動物園', '15:20', ''], [10, '動物園', '萬芳醫院', '15:31', '']], 'stations': ['動物園', '木柵', '萬芳社區', '萬芳醫院'], 'telecom': 'CHT', 'protocol': 'UDP', 'length': [250, 'byte'], 'bitrate': [1, 'Mbps'], 'notes': ''}}\n",
      "2023-06-12 1\n",
      "{'UDP_Bandlock_8S_Phone': {'route': 'BR', 'devices': {'sm00': 'All', 'sm01': 'B3', 'sm02': 'B7', 'sm03': 'B8', 'sm04': 'B3B7', 'sm05': 'B3B8', 'sm06': 'B7B8', 'sm07': 'LTE'}, 'ods': [[0, 'Origin Station', 'Destination Station', 'Departure Time', 'Notes'], [1, '萬芳醫院', '動物園', '16:30', ''], [2, '動物園', '萬芳醫院', '16:39', ''], [3, '萬芳醫院', '動物園', '16:51', ''], [4, '動物園', '萬芳醫院', '17:00', ''], [5, '萬芳醫院', '動物園', '17:07', ''], [6, '動物園', '萬芳醫院', '17:16', ''], [7, '萬芳醫院', '動物園', '17:23', ''], [8, '動物園', '萬芳醫院', '17:31', ''], [9, '萬芳醫院', '動物園', '17:37', ''], [10, '動物園', '萬芳醫院', '17:44', '']], 'stations': ['動物園', '木柵', '萬芳社區', '萬芳醫院'], 'telecom': 'CHT', 'protocol': 'UDP', 'length': [250, 'byte'], 'bitrate': [1, 'Mbps'], 'notes': ''}}\n",
      "2023-06-13 1\n",
      "{'UDP_Bandlock_8S_Phone': {'route': 'BR', 'devices': {'sm00': 'All', 'sm01': 'B3', 'sm02': 'B7', 'sm03': 'B8', 'sm04': 'B3B7', 'sm05': 'B3B8', 'sm06': 'B7B8', 'sm07': 'LTE'}, 'ods': [[0, 'Origin Station', 'Destination Station', 'Departure Time', 'Notes'], [2, '動物園', '萬芳醫院', '15:08', ''], [3, '萬芳醫院', '動物園', '15:16', ''], [4, '動物園', '萬芳醫院', '15:24', ''], [5, '萬芳醫院', '動物園', '15:31', ''], [6, '動物園', '萬芳醫院', '15:39', ''], [7, '萬芳醫院', '動物園', '15:46', ''], [8, '動物園', '萬芳醫院', '15:54', ''], [9, '萬芳醫院', '動物園', '16:01', ''], [10, '動物園', '萬芳醫院', '16:11', '']], 'stations': ['動物園', '木柵', '萬芳社區', '萬芳醫院'], 'telecom': 'CHT', 'protocol': 'UDP', 'length': [250, 'byte'], 'bitrate': [1, 'Mbps'], 'notes': ''}}\n",
      "2023-06-15 5\n",
      "{'UDP_Bandlock_B1_B3_B7_B8_Dupl_Phone': {'route': 'BR', 'devices': {'sm00': 'B1', 'sm01': 'B1', 'sm02': 'B3', 'sm03': 'B3', 'sm04': 'B7', 'sm05': 'B7', 'sm06': 'B8', 'sm07': 'B8'}, 'ods': [[0, 'Origin Station', 'Destination Station', 'Departure Time', 'Notes'], [1, '萬芳醫院', '動物園', '15:00', ''], [2, '動物園', '萬芳醫院', '15:09', ''], [3, '萬芳醫院', '動物園', '15:15', ''], [4, '動物園', '萬芳醫院', '14:24', '']], 'stations': ['動物園', '木柵', '萬芳社區', '萬芳醫院'], 'telecom': 'CHT', 'protocol': 'UDP', 'length': [250, 'byte'], 'bitrate': [1, 'Mbps'], 'notes': ''}}\n",
      "{'UDP_Bandlock_All_B3_B7_B8_Dupl_Phone': {'route': 'BR', 'devices': {'sm00': 'All', 'sm01': 'All', 'sm02': 'B3', 'sm03': 'B3', 'sm04': 'B7', 'sm05': 'B7', 'sm06': 'B8', 'sm07': 'B8'}, 'ods': [[0, 'Origin Station', 'Destination Station', 'Departure Time', 'Notes'], [1, '萬芳醫院', '動物園', '15:30', ''], [2, '動物園', '萬芳醫院', '15:39', ''], [3, '萬芳醫院', '動物園', '15:45', ''], [4, '動物園', '萬芳醫院', '15:54', '']], 'stations': ['動物園', '木柵', '萬芳社區', '萬芳醫院'], 'telecom': 'CHT', 'protocol': 'UDP', 'length': [250, 'byte'], 'bitrate': [1, 'Mbps'], 'notes': ''}}\n",
      "{'UDP_Bandlock_LTE_B3_B7_B8_Dupl_Phone': {'route': 'BR', 'devices': {'sm00': 'LTE', 'sm01': 'LTE', 'sm02': 'B3', 'sm03': 'B3', 'sm04': 'B7', 'sm05': 'B7', 'sm06': 'B8', 'sm07': 'B8'}, 'ods': [[0, 'Origin Station', 'Destination Station', 'Departure Time', 'Notes'], [1, '萬芳醫院', '動物園', '16:00', ''], [2, '動物園', '萬芳醫院', '16:07', ''], [3, '萬芳醫院', '動物園', '16:20', ''], [4, '動物園', '萬芳醫院', '16:26', ''], [5, '萬芳醫院', '動物園', '16:34', ''], [6, '動物園', '萬芳醫院', '16:42', '']], 'stations': ['動物園', '木柵', '萬芳社區', '萬芳醫院'], 'telecom': 'CHT', 'protocol': 'UDP', 'length': [250, 'byte'], 'bitrate': [1, 'Mbps'], 'notes': ''}}\n",
      "{'UDP_Bandlock_LTE_LTEb3_LTEb7_LTEb8_Dupl_Phone': {'route': 'BR', 'devices': {'sm00': 'LTE', 'sm01': 'LTE', 'sm02': 'LTEb3', 'sm03': 'LTEb3', 'sm04': 'LTEb7', 'sm05': 'LTEb7', 'sm06': 'LTEb8', 'sm07': 'LTEb8'}, 'ods': [[0, 'Origin Station', 'Destination Station', 'Departure Time', 'Notes'], [1, '萬芳醫院', '動物園', '16:56', ''], [2, '動物園', '萬芳醫院', '17:03', ''], [3, '萬芳醫院', '動物園', '17:12', 'sm03 adb disconnected (keep transferring packets but miss mi2log)'], [4, '動物園', '萬芳醫院', '17:22', '']], 'stations': ['動物園', '木柵', '萬芳社區', '萬芳醫院'], 'telecom': 'CHT', 'protocol': 'UDP', 'length': [250, 'byte'], 'bitrate': [1, 'Mbps'], 'notes': ''}}\n",
      "{'UDP_Bandlock_LTEb1_LTEb3_LTEb7_LTEb8_Dupl_Phone': {'route': 'BR', 'devices': {'sm00': 'LTEb1', 'sm01': 'LTEb1', 'sm02': 'LTEb3', 'sm03': 'LTEb3', 'sm04': 'LTEb7', 'sm05': 'LTEb7', 'sm06': 'LTEb8', 'sm07': 'LTEb8'}, 'ods': [[0, 'Origin Station', 'Destination Station', 'Departure Time', 'Notes'], [1, '萬芳醫院', '動物園', '17:30', ''], [2, '動物園', '萬芳醫院', '17:38', ''], [3, '萬芳醫院', '動物園', '17:44', ''], [4, '動物園', '萬芳醫院', '17:52', '']], 'stations': ['動物園', '木柵', '萬芳社區', '萬芳醫院'], 'telecom': 'CHT', 'protocol': 'UDP', 'length': [250, 'byte'], 'bitrate': [1, 'Mbps'], 'notes': ''}}\n",
      "2023-08-16 1\n",
      "{'UDP_Phone_LTE_NR': {'route': 'BR', 'devices': {'sm00': 'LTE', 'sm01': 'All'}, 'ods': [[0, 'Origin Station', 'Destination Station', 'Departure Time', 'Notes'], [1, '辛亥', '動物園', '15:03', ''], [2, '動物園', '辛亥', '15:14', ''], [3, '辛亥', '動物園', '15:29', ''], [4, '動物園', '辛亥', '15:39', ''], [5, '辛亥', '動物園', '15:54', ''], [6, '動物園', '辛亥', '16:07', '']], 'stations': ['動物園', '木柵', '萬芳社區', '萬芳醫院', '辛亥'], 'telecom': 'CHT', 'protocol': 'UDP', 'length': [250, 'byte'], 'bitrate': [1, 'Mbps'], 'notes': ''}}\n",
      "2023-08-21 1\n",
      "{'UDP_Phone_NR_LTE': {'route': 'BR', 'devices': {'sm00': 'All', 'sm01': 'LTE'}, 'ods': [[0, 'Origin Station', 'Destination Station', 'Departure Time', 'Notes'], [1, '科技大樓', '中山國中', '14:33', ''], [2, '中山國中', '科技大樓', '14:44', ''], [3, '科技大樓', '中山國中', '14:58', ''], [4, '中山國中', '科技大樓', '15:09', ''], [5, '科技大樓', '中山國中', '15:23', ''], [6, '中山國中', '科技大樓', '15:34', '']], 'stations': ['科技大樓', '大安', '忠孝復興', '南京復興', '中山國中'], 'telecom': 'CHT', 'protocol': 'UDP', 'length': [250, 'byte'], 'bitrate': [1, 'Mbps'], 'notes': ''}}\n",
      "2023-09-12-2 1\n",
      "{'UDP_Bandlock_9S_Phone_Brown': {'skip': False, 'route': 'BR', 'devices': {'sm00': 'All', 'sm01': 'All', 'sm02': 'B3', 'sm03': 'B7', 'sm04': 'B8', 'sm05': 'B3B7', 'sm06': 'B3B8', 'sm07': 'B7B8', 'sm08': 'LTE'}, 'ods': [[0, 'Origin Station', 'Destination Station', 'Departure Time', 'Notes'], [1, '動物園', '南港展覽館', '13:34', '到木柵才想起要開GPS'], [2, '南港展覽館', '動物園', '14:52', '']], 'stations': ['動物園', '木柵', '萬芳社區', '萬芳醫院', '辛亥', '麟光', '六張犁', '科技大樓', '大安', '忠孝復興', '南京復興', '中山國中', '松山機場', '大直', '劍南路', '西湖', '港墘', '文德', '內湖', '大湖公園', '葫洲', '東湖', '南港軟體園區', '南港展覽館'], 'ue': 'Phone', 'sync': None, 'telecom': 'CHT', 'protocol': 'UDP', 'length': [250, 'byte'], 'bitrate': [1, 'Mbps'], 'notes': ''}}\n",
      "2023-09-21 1\n",
      "{'UDP_Bandlock_9S_Phone_Brown': {'route': 'BR', 'devices': {'sm00': 'All', 'sm01': 'All', 'sm02': 'B3', 'sm03': 'B7', 'sm04': 'B8', 'sm05': 'B3B7', 'sm06': 'B3B8', 'sm07': 'B7B8', 'sm08': 'LTE'}, 'ods': [[0, 'Origin Station', 'Destination Station', 'Departure Time', 'Notes'], [1, '動物園', '南港展覽館', '14:29', ''], [2, '南港展覽館', '動物園', '15:09', '']], 'stations': ['動物園', '木柵', '萬芳社區', '萬芳醫院', '辛亥', '麟光', '六張犁', '科技大樓', '大安', '忠孝復興', '南京復興', '中山國中', '松山機場', '大直', '劍南路', '西湖', '港墘', '文德', '內湖', '大湖公園', '葫洲', '東湖', '南港軟體園區', '南港展覽館'], 'telecom': 'CHT', 'protocol': 'UDP', 'length': [250, 'byte'], 'bitrate': [1, 'Mbps'], 'notes': ''}}\n",
      "2023-10-05 1\n",
      "{'UDP_Bandlock_9S_Phone_Green': {'route': 'G', 'devices': {'sm00': 'All', 'sm01': 'All', 'sm02': 'B3', 'sm03': 'B7', 'sm04': 'B8', 'sm05': 'B3B7', 'sm06': 'B3B8', 'sm07': 'B7B8', 'sm08': 'LTE'}, 'ods': [[0, 'Origin Station', 'Destination Station', 'Departure Time', 'Notes'], [1, '新店區公所', '松山', '14:24', '本來要在新店開始，但有點意外發生，不想回頭搭'], [2, '松山', '新店', '15:14', '']], 'stations': ['新店', '新店區公所', '七張', '大坪林', '景美', '萬隆', '公館', '台電大樓', '古亭', '中正紀念堂', '小南門', '西門', '北門', '中山', '松江南京', '南京復興', '台北小巨蛋', '南京三民', '松山'], 'telecom': 'CHT', 'protocol': 'UDP', 'length': [250, 'byte'], 'bitrate': [1, 'Mbps'], 'notes': ''}}\n",
      "2023-10-19 1\n",
      "{'UDP_Bandlock_9S_Phone_Red': {'route': 'R', 'devices': {'sm00': 'All', 'sm01': 'All', 'sm02': 'B3', 'sm03': 'B7', 'sm04': 'B8', 'sm05': 'B3B7', 'sm06': 'B3B8', 'sm07': 'B7B8', 'sm08': 'LTE'}, 'ods': [[0, 'Origin Station', 'Destination Station', 'Departure Time', 'Notes'], [1, '象山', '淡水', '14:37', ''], [2, '淡水', '象山', '15:54', '']], 'stations': ['象山', '台北101/世貿', '信義安和', '大安', '大安森林公園', '東門', '中正紀念堂', '台大醫院', '台北車站', '中山', '雙連', '民權西路', '圓山', '劍潭', '士林', '芝山', '明德', '石牌', '唭哩岸', '奇岩', '北投', '復興崗', '忠義', '關渡', '竹圍', '紅樹林', '淡水'], 'telecom': 'CHT', 'protocol': 'UDP', 'length': [250, 'byte'], 'bitrate': [1, 'Mbps'], 'notes': ''}}\n",
      "2023-10-26 1\n",
      "{'UDP_Bandlock_9S_Phone_Airport': {'route': 'A', 'devices': {'sm00': 'All', 'sm01': 'All', 'sm02': 'B3', 'sm03': 'B7', 'sm04': 'B8', 'sm05': 'B3B7', 'sm06': 'B3B8', 'sm07': 'B7B8', 'sm08': 'LTE'}, 'ods': [[0, 'Origin Station', 'Destination Station', 'Departure Time', 'Notes'], [1, '台北車站', '機場第二航廈', '13:30', '直達車'], [2, '機場第二航廈', '台北車站', '14:25', '直達車']], 'stations': ['台北車站', '三重', '新北產業園區', '新莊副都心', '泰山', '泰山貴和', '體育大學', '長庚醫院', '林口', '山鼻', '坑口', '機場第一航廈', '機場第二航廈'], 'telecom': 'CHT', 'protocol': 'UDP', 'length': [250, 'byte'], 'bitrate': [1, 'Mbps'], 'notes': ''}}\n",
      "2023-11-01 1\n",
      "{'UDP_Bandlock_9S_Phone_Airport': {'route': 'A', 'devices': {'sm00': 'All', 'sm01': 'All', 'sm02': 'B3', 'sm03': 'B7', 'sm04': 'B8', 'sm05': 'B3B7', 'sm06': 'B3B8', 'sm07': 'B7B8', 'sm08': 'LTE'}, 'ods': [[0, 'Origin Station', 'Destination Station', 'Departure Time', 'Notes'], [1, '台北車站', '機場第二航廈', '14:52', '普通車'], [2, '機場第二航廈', '台北車站', '16:04', '普通車']], 'stations': ['台北車站', '三重', '新北產業園區', '新莊副都心', '泰山', '泰山貴和', '體育大學', '長庚醫院', '林口', '山鼻', '坑口', '機場第一航廈', '機場第二航廈'], 'telecom': 'CHT', 'protocol': 'UDP', 'length': [250, 'byte'], 'bitrate': [1, 'Mbps'], 'notes': ''}}\n",
      "2023-11-02 1\n",
      "{'UDP_Bandlock_9S_Phone_Airport': {'route': 'A', 'devices': {'sm00': 'All', 'sm01': 'All', 'sm02': 'B3', 'sm03': 'B7', 'sm04': 'B8', 'sm05': 'B3B7', 'sm06': 'B3B8', 'sm07': 'B7B8', 'sm08': 'LTE'}, 'ods': [[0, 'Origin Station', 'Destination Station', 'Departure Time', 'Notes'], [1, '體育大學', '機場第二航廈', '16:45', '普通車'], [2, '機場第二航廈', '台北車站', '17:55', '直達車']], 'stations': ['台北車站', '三重', '新北產業園區', '新莊副都心', '泰山', '泰山貴和', '體育大學', '長庚醫院', '林口', '山鼻', '坑口', '機場第一航廈', '機場第二航廈'], 'telecom': 'CHT', 'protocol': 'UDP', 'length': [250, 'byte'], 'bitrate': [1, 'Mbps'], 'notes': ''}}\n",
      "2023-11-09 1\n",
      "{'UDP_Bandlock_9S_Phone_Brown': {'route': 'BR', 'devices': {'sm00': 'All', 'sm01': 'All', 'sm02': 'B3', 'sm03': 'B7', 'sm04': 'B8', 'sm05': 'B3B7', 'sm06': 'B3B8', 'sm07': 'B7B8', 'sm08': 'LTE'}, 'ods': [[0, 'Origin Station', 'Destination Station', 'Departure Time', 'Notes'], [1, '木柵', '南港展覽館', '12:21', ''], [2, '南港展覽館', '動物園', '13:41', '']], 'stations': ['動物園', '木柵', '萬芳社區', '萬芳醫院', '辛亥', '麟光', '六張犁', '科技大樓', '大安', '忠孝復興', '南京復興', '中山國中', '松山機場', '大直', '劍南路', '西湖', '港墘', '文德', '內湖', '大湖公園', '葫洲', '東湖', '南港軟體園區', '南港展覽館'], 'telecom': 'CHT', 'protocol': 'UDP', 'length': [250, 'byte'], 'bitrate': [1, 'Mbps'], 'notes': ''}}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "# Specify root directory\n",
    "root_dir = \"/Users/jackbedford/Desktop/MOXA/Code/data\"\n",
    "\n",
    "# Collect dates\n",
    "dates = [s for s in sorted(os.listdir(root_dir)) if os.path.isdir(os.path.join(root_dir, s)) and s != 'backup']\n",
    "date_dirs = [os.path.join(root_dir, s) for s in dates]\n",
    "\n",
    "for date, date_dir in zip(dates, date_dirs):\n",
    "    # Specify the path to your JSON file\n",
    "    date = os.path.basename(date_dir)\n",
    "    json_filepath = os.path.join(date_dir, f'{date}.json')\n",
    "    \n",
    "    # Read the JSON file and load its contents into a dictionary\n",
    "    with open(json_filepath, 'r', encoding='utf-8') as json_file:\n",
    "        my_dict = json.load(json_file)\n",
    "    \n",
    "    if not my_dict:\n",
    "        continue\n",
    "        \n",
    "    print(date, len(my_dict))\n",
    "    \n",
    "    for expr, item in my_dict.items():\n",
    "        print({expr: item})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select Dates\n",
    "# sel_dates = [s for s in dates if s >= '2023-09-12']\n",
    "# sel_dates = [s for s in dates if s < '2023-09-12']\n",
    "# sel_dates = [s for s in dates if s >= '2023-08-16' and s < '2023-09-12']\n",
    "# sel_dates = dates[:5]\n",
    "# sel_dates = dates[-8:]\n",
    "sel_dates = ['2023-09-12-2']\n",
    "# sel_dates = dates[:]\n",
    "# exc_dates = ['2023-06-12', '2023-06-13']\n",
    "exc_dates = []\n",
    "date_dirs = [os.path.join(root_dir, s) for s in sel_dates if s not in exc_dates]\n",
    "\n",
    "# Select Experiment Names\n",
    "# sel_exps = ['UDP_Bandlock_9S_Phone_Brown', 'UDP_Bandlock_9S_Phone_Airport']\n",
    "sel_exps = []\n",
    "exc_exps = ['Modem_Action_Test', 'Control_Group', 'Control_Group2', 'Control_Group3']\n",
    "# exc_exps = []\n",
    "\n",
    "# Select Routes\n",
    "# sel_routes = ['BR']\n",
    "sel_routes = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-09-12-2 1\n",
      "{'UDP_Bandlock_9S_Phone_Brown': {'skip': False, 'route': 'BR', 'devices': {'sm00': 'All', 'sm01': 'All', 'sm02': 'B3', 'sm03': 'B7', 'sm04': 'B8', 'sm05': 'B3B7', 'sm06': 'B3B8', 'sm07': 'B7B8', 'sm08': 'LTE'}, 'ods': [[0, 'Origin Station', 'Destination Station', 'Departure Time', 'Notes'], [1, '動物園', '南港展覽館', '13:34', '到木柵才想起要開GPS'], [2, '南港展覽館', '動物園', '14:52', '']], 'stations': ['動物園', '木柵', '萬芳社區', '萬芳醫院', '辛亥', '麟光', '六張犁', '科技大樓', '大安', '忠孝復興', '南京復興', '中山國中', '松山機場', '大直', '劍南路', '西湖', '港墘', '文德', '內湖', '大湖公園', '葫洲', '東湖', '南港軟體園區', '南港展覽館'], 'ue': 'Phone', 'sync': None, 'telecom': 'CHT', 'protocol': 'UDP', 'length': [250, 'byte'], 'bitrate': [1, 'Mbps'], 'notes': ''}}\n"
     ]
    }
   ],
   "source": [
    "# Collect Experiments\n",
    "exps_dict = {}\n",
    "\n",
    "for date_dir in date_dirs:\n",
    "    date = os.path.basename(date_dir)\n",
    "    \n",
    "    # Specify the path to your JSON file\n",
    "    json_filepath = os.path.join(date_dir, f'{date}.json')\n",
    "    \n",
    "    # Read the JSON file and load its contents into a dictionary\n",
    "    with open(json_filepath, 'r', encoding='utf-8') as json_file:\n",
    "        my_dict = json.load(json_file)\n",
    "    \n",
    "    if not my_dict:\n",
    "        continue\n",
    "    \n",
    "    for i, (expr, item) in enumerate(my_dict.items()):\n",
    "        if len(sel_exps) != 0 and expr not in sel_exps:\n",
    "            continue\n",
    "        \n",
    "        if len(exc_exps) != 0 and expr in exc_exps:\n",
    "            continue\n",
    "        \n",
    "        if len(sel_routes) != 0 and item['route'] not in sel_routes:\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            exps_dict[date] = {**exps_dict[date], **{expr: item}}\n",
    "        except:\n",
    "            exps_dict[date] = {expr: item}\n",
    "\n",
    "for date, exps in exps_dict.items():\n",
    "    # print(date, len(exps), exps)\n",
    "    print(date, len(exps))\n",
    "    \n",
    "    for expr, item in exps.items():\n",
    "        print({expr: item})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '/Users/jackbedford/Desktop/MOXA/Code/data/2023-09-12-2/UDP_Bandlock_9S_Phone_Brown/sm00/#01/data/diag_log_sm00_2023-09-12_13-34-15_rrc.csv',\n",
      "  '/Users/jackbedford/Desktop/MOXA/Code/data/2023-09-12-2/UDP_Bandlock_9S_Phone_Brown/sm00/#01/data/udp_dnlk_loss_latency.csv',\n",
      "  '/Users/jackbedford/Desktop/MOXA/Code/data/2023-09-12-2/UDP_Bandlock_9S_Phone_Brown/sm00/#01/data/udp_uplk_loss_latency.csv'),\n",
      " (1,\n",
      "  '/Users/jackbedford/Desktop/MOXA/Code/data/2023-09-12-2/UDP_Bandlock_9S_Phone_Brown/sm00/#02/data/diag_log_sm00_2023-09-12_14-52-28_rrc.csv',\n",
      "  '/Users/jackbedford/Desktop/MOXA/Code/data/2023-09-12-2/UDP_Bandlock_9S_Phone_Brown/sm00/#02/data/udp_dnlk_loss_latency.csv',\n",
      "  '/Users/jackbedford/Desktop/MOXA/Code/data/2023-09-12-2/UDP_Bandlock_9S_Phone_Brown/sm00/#02/data/udp_uplk_loss_latency.csv'),\n",
      " (2,\n",
      "  '/Users/jackbedford/Desktop/MOXA/Code/data/2023-09-12-2/UDP_Bandlock_9S_Phone_Brown/sm01/#01/data/diag_log_sm01_2023-09-12_13-34-15_rrc.csv',\n",
      "  '/Users/jackbedford/Desktop/MOXA/Code/data/2023-09-12-2/UDP_Bandlock_9S_Phone_Brown/sm01/#01/data/udp_dnlk_loss_latency.csv',\n",
      "  '/Users/jackbedford/Desktop/MOXA/Code/data/2023-09-12-2/UDP_Bandlock_9S_Phone_Brown/sm01/#01/data/udp_uplk_loss_latency.csv'),\n",
      " (3,\n",
      "  '/Users/jackbedford/Desktop/MOXA/Code/data/2023-09-12-2/UDP_Bandlock_9S_Phone_Brown/sm01/#02/data/diag_log_sm01_2023-09-12_14-52-27_rrc.csv',\n",
      "  '/Users/jackbedford/Desktop/MOXA/Code/data/2023-09-12-2/UDP_Bandlock_9S_Phone_Brown/sm01/#02/data/udp_dnlk_loss_latency.csv',\n",
      "  '/Users/jackbedford/Desktop/MOXA/Code/data/2023-09-12-2/UDP_Bandlock_9S_Phone_Brown/sm01/#02/data/udp_uplk_loss_latency.csv'),\n",
      " (4,\n",
      "  '/Users/jackbedford/Desktop/MOXA/Code/data/2023-09-12-2/UDP_Bandlock_9S_Phone_Brown/sm02/#01/data/diag_log_sm02_2023-09-12_13-34-15_rrc.csv',\n",
      "  '/Users/jackbedford/Desktop/MOXA/Code/data/2023-09-12-2/UDP_Bandlock_9S_Phone_Brown/sm02/#01/data/udp_dnlk_loss_latency.csv',\n",
      "  '/Users/jackbedford/Desktop/MOXA/Code/data/2023-09-12-2/UDP_Bandlock_9S_Phone_Brown/sm02/#01/data/udp_uplk_loss_latency.csv'),\n",
      " (5,\n",
      "  '/Users/jackbedford/Desktop/MOXA/Code/data/2023-09-12-2/UDP_Bandlock_9S_Phone_Brown/sm02/#02/data/diag_log_sm02_2023-09-12_14-52-27_rrc.csv',\n",
      "  '/Users/jackbedford/Desktop/MOXA/Code/data/2023-09-12-2/UDP_Bandlock_9S_Phone_Brown/sm02/#02/data/udp_dnlk_loss_latency.csv',\n",
      "  '/Users/jackbedford/Desktop/MOXA/Code/data/2023-09-12-2/UDP_Bandlock_9S_Phone_Brown/sm02/#02/data/udp_uplk_loss_latency.csv'),\n",
      " (6,\n",
      "  '/Users/jackbedford/Desktop/MOXA/Code/data/2023-09-12-2/UDP_Bandlock_9S_Phone_Brown/sm03/#01/data/diag_log_sm03_2023-09-12_13-34-15_rrc.csv',\n",
      "  '/Users/jackbedford/Desktop/MOXA/Code/data/2023-09-12-2/UDP_Bandlock_9S_Phone_Brown/sm03/#01/data/udp_dnlk_loss_latency.csv',\n",
      "  '/Users/jackbedford/Desktop/MOXA/Code/data/2023-09-12-2/UDP_Bandlock_9S_Phone_Brown/sm03/#01/data/udp_uplk_loss_latency.csv'),\n",
      " (7,\n",
      "  '/Users/jackbedford/Desktop/MOXA/Code/data/2023-09-12-2/UDP_Bandlock_9S_Phone_Brown/sm03/#02/data/diag_log_sm03_2023-09-12_14-52-28_rrc.csv',\n",
      "  '/Users/jackbedford/Desktop/MOXA/Code/data/2023-09-12-2/UDP_Bandlock_9S_Phone_Brown/sm03/#02/data/udp_dnlk_loss_latency.csv',\n",
      "  '/Users/jackbedford/Desktop/MOXA/Code/data/2023-09-12-2/UDP_Bandlock_9S_Phone_Brown/sm03/#02/data/udp_uplk_loss_latency.csv'),\n",
      " (8,\n",
      "  '/Users/jackbedford/Desktop/MOXA/Code/data/2023-09-12-2/UDP_Bandlock_9S_Phone_Brown/sm04/#01/data/diag_log_sm04_2023-09-12_13-34-15_rrc.csv',\n",
      "  '/Users/jackbedford/Desktop/MOXA/Code/data/2023-09-12-2/UDP_Bandlock_9S_Phone_Brown/sm04/#01/data/udp_dnlk_loss_latency.csv',\n",
      "  '/Users/jackbedford/Desktop/MOXA/Code/data/2023-09-12-2/UDP_Bandlock_9S_Phone_Brown/sm04/#01/data/udp_uplk_loss_latency.csv'),\n",
      " (9,\n",
      "  '/Users/jackbedford/Desktop/MOXA/Code/data/2023-09-12-2/UDP_Bandlock_9S_Phone_Brown/sm04/#02/data/diag_log_sm04_2023-09-12_14-52-28_rrc.csv',\n",
      "  '/Users/jackbedford/Desktop/MOXA/Code/data/2023-09-12-2/UDP_Bandlock_9S_Phone_Brown/sm04/#02/data/udp_dnlk_loss_latency.csv',\n",
      "  '/Users/jackbedford/Desktop/MOXA/Code/data/2023-09-12-2/UDP_Bandlock_9S_Phone_Brown/sm04/#02/data/udp_uplk_loss_latency.csv'),\n",
      " (10,\n",
      "  '/Users/jackbedford/Desktop/MOXA/Code/data/2023-09-12-2/UDP_Bandlock_9S_Phone_Brown/sm05/#01/data/diag_log_sm05_2023-09-12_13-34-15_rrc.csv',\n",
      "  '/Users/jackbedford/Desktop/MOXA/Code/data/2023-09-12-2/UDP_Bandlock_9S_Phone_Brown/sm05/#01/data/udp_dnlk_loss_latency.csv',\n",
      "  '/Users/jackbedford/Desktop/MOXA/Code/data/2023-09-12-2/UDP_Bandlock_9S_Phone_Brown/sm05/#01/data/udp_uplk_loss_latency.csv'),\n",
      " (11,\n",
      "  '/Users/jackbedford/Desktop/MOXA/Code/data/2023-09-12-2/UDP_Bandlock_9S_Phone_Brown/sm05/#02/data/diag_log_sm05_2023-09-12_14-52-28_rrc.csv',\n",
      "  '/Users/jackbedford/Desktop/MOXA/Code/data/2023-09-12-2/UDP_Bandlock_9S_Phone_Brown/sm05/#02/data/udp_dnlk_loss_latency.csv',\n",
      "  '/Users/jackbedford/Desktop/MOXA/Code/data/2023-09-12-2/UDP_Bandlock_9S_Phone_Brown/sm05/#02/data/udp_uplk_loss_latency.csv'),\n",
      " (12,\n",
      "  '/Users/jackbedford/Desktop/MOXA/Code/data/2023-09-12-2/UDP_Bandlock_9S_Phone_Brown/sm06/#01/data/diag_log_sm06_2023-09-12_13-34-15_rrc.csv',\n",
      "  '/Users/jackbedford/Desktop/MOXA/Code/data/2023-09-12-2/UDP_Bandlock_9S_Phone_Brown/sm06/#01/data/udp_dnlk_loss_latency.csv',\n",
      "  '/Users/jackbedford/Desktop/MOXA/Code/data/2023-09-12-2/UDP_Bandlock_9S_Phone_Brown/sm06/#01/data/udp_uplk_loss_latency.csv'),\n",
      " (13,\n",
      "  '/Users/jackbedford/Desktop/MOXA/Code/data/2023-09-12-2/UDP_Bandlock_9S_Phone_Brown/sm06/#02/data/diag_log_sm06_2023-09-12_14-52-28_rrc.csv',\n",
      "  '/Users/jackbedford/Desktop/MOXA/Code/data/2023-09-12-2/UDP_Bandlock_9S_Phone_Brown/sm06/#02/data/udp_dnlk_loss_latency.csv',\n",
      "  '/Users/jackbedford/Desktop/MOXA/Code/data/2023-09-12-2/UDP_Bandlock_9S_Phone_Brown/sm06/#02/data/udp_uplk_loss_latency.csv'),\n",
      " (14,\n",
      "  '/Users/jackbedford/Desktop/MOXA/Code/data/2023-09-12-2/UDP_Bandlock_9S_Phone_Brown/sm07/#01/data/diag_log_sm07_2023-09-12_13-34-15_rrc.csv',\n",
      "  '/Users/jackbedford/Desktop/MOXA/Code/data/2023-09-12-2/UDP_Bandlock_9S_Phone_Brown/sm07/#01/data/udp_dnlk_loss_latency.csv',\n",
      "  '/Users/jackbedford/Desktop/MOXA/Code/data/2023-09-12-2/UDP_Bandlock_9S_Phone_Brown/sm07/#01/data/udp_uplk_loss_latency.csv'),\n",
      " (15,\n",
      "  '/Users/jackbedford/Desktop/MOXA/Code/data/2023-09-12-2/UDP_Bandlock_9S_Phone_Brown/sm07/#02/data/diag_log_sm07_2023-09-12_14-52-28_rrc.csv',\n",
      "  '/Users/jackbedford/Desktop/MOXA/Code/data/2023-09-12-2/UDP_Bandlock_9S_Phone_Brown/sm07/#02/data/udp_dnlk_loss_latency.csv',\n",
      "  '/Users/jackbedford/Desktop/MOXA/Code/data/2023-09-12-2/UDP_Bandlock_9S_Phone_Brown/sm07/#02/data/udp_uplk_loss_latency.csv'),\n",
      " (16,\n",
      "  '/Users/jackbedford/Desktop/MOXA/Code/data/2023-09-12-2/UDP_Bandlock_9S_Phone_Brown/sm08/#01/data/diag_log_sm08_2023-09-12_13-34-15_rrc.csv',\n",
      "  '/Users/jackbedford/Desktop/MOXA/Code/data/2023-09-12-2/UDP_Bandlock_9S_Phone_Brown/sm08/#01/data/udp_dnlk_loss_latency.csv',\n",
      "  '/Users/jackbedford/Desktop/MOXA/Code/data/2023-09-12-2/UDP_Bandlock_9S_Phone_Brown/sm08/#01/data/udp_uplk_loss_latency.csv'),\n",
      " (17,\n",
      "  '/Users/jackbedford/Desktop/MOXA/Code/data/2023-09-12-2/UDP_Bandlock_9S_Phone_Brown/sm08/#02/data/diag_log_sm08_2023-09-12_14-52-28_rrc.csv',\n",
      "  '/Users/jackbedford/Desktop/MOXA/Code/data/2023-09-12-2/UDP_Bandlock_9S_Phone_Brown/sm08/#02/data/udp_dnlk_loss_latency.csv',\n",
      "  '/Users/jackbedford/Desktop/MOXA/Code/data/2023-09-12-2/UDP_Bandlock_9S_Phone_Brown/sm08/#02/data/udp_uplk_loss_latency.csv')]\n"
     ]
    }
   ],
   "source": [
    "filepaths = []\n",
    "\n",
    "i = 0\n",
    "for date, exps in exps_dict.items():\n",
    "    # print(date, len(exps), exps)\n",
    "    # print(date, len(exps))\n",
    "    \n",
    "    for name, expr in exps.items():\n",
    "        for dev in expr['devices'].keys():\n",
    "            for trip in expr['ods'][1:]:\n",
    "                trip = '#{:02d}'.format(trip[0])\n",
    "                data_dir = os.path.join(root_dir, date, name, dev, trip, 'data')\n",
    "                # print(data_dir, os.path.isdir(data_dir))\n",
    "                \n",
    "                rrc_filepath = [os.path.join(data_dir, s) for s in os.listdir(data_dir) if s.endswith('rrc.csv')][0]\n",
    "                dl_filepath = os.path.join(data_dir, 'udp_dnlk_loss_latency.csv')\n",
    "                ul_filepath = os.path.join(data_dir, 'udp_uplk_loss_latency.csv')\n",
    "                # print(rrc_filepath, os.path.isfile(rrc_filepath))\n",
    "                # print(dl_filepath, os.path.isfile(dl_filepath))\n",
    "                # print(ul_filepath, os.path.isfile(ul_filepath))\n",
    "                \n",
    "                filepaths.append((i, rrc_filepath, dl_filepath, ul_filepath))\n",
    "                i += 1\n",
    "\n",
    "pprint(filepaths, sort_dicts=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ('/Users/jackbedford/Desktop/MOXA/Code/data/2023-09-12-2/UDP_Bandlock_9S_Phone_Brown/sm00/#01/data/diag_log_sm00_2023-09-12_13-34-15_rrc.csv', '/Users/jackbedford/Desktop/MOXA/Code/data/2023-09-12-2/UDP_Bandlock_9S_Phone_Brown/sm00/#01/data/udp_dnlk_loss_latency.csv', '/Users/jackbedford/Desktop/MOXA/Code/data/2023-09-12-2/UDP_Bandlock_9S_Phone_Brown/sm00/#01/data/udp_uplk_loss_latency.csv')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vy/w6g3hxgj76s0gzty27t2d6gm0000gn/T/ipykernel_14959/2677595655.py:25: DtypeWarning: Columns (26,53) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_ho, _ = mi_parse_handover(pd.read_csv(rrc_file), radical=True, endfill=True)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'absoluteFrequencySSB'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/envs/moxa/lib/python3.8/site-packages/pandas/core/indexes/base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3801\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/moxa/lib/python3.8/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/moxa/lib/python3.8/site-packages/pandas/_libs/index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'absoluteFrequencySSB'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/Users/jackbedford/Desktop/MOXA/Code/wmnl-handoff-research/analysis/2023-11-21-label_ho.ipynb Cell 17\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jackbedford/Desktop/MOXA/Code/wmnl-handoff-research/analysis/2023-11-21-label_ho.ipynb#X22sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39mfor\u001b[39;00m i, rrc_file, dl_file, ul_file \u001b[39min\u001b[39;00m filepaths:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jackbedford/Desktop/MOXA/Code/wmnl-handoff-research/analysis/2023-11-21-label_ho.ipynb#X22sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     \u001b[39m########### in for loop (iterating exprs) ##### start\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jackbedford/Desktop/MOXA/Code/wmnl-handoff-research/analysis/2023-11-21-label_ho.ipynb#X22sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     \u001b[39mprint\u001b[39m(i, (rrc_file, dl_file, ul_file))\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/jackbedford/Desktop/MOXA/Code/wmnl-handoff-research/analysis/2023-11-21-label_ho.ipynb#X22sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     df_ho, _ \u001b[39m=\u001b[39m mi_parse_handover(pd\u001b[39m.\u001b[39;49mread_csv(rrc_file), radical\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, endfill\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jackbedford/Desktop/MOXA/Code/wmnl-handoff-research/analysis/2023-11-21-label_ho.ipynb#X22sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     df_ho\u001b[39m.\u001b[39mto_csv(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mdirname(rrc_file), \u001b[39m'\u001b[39m\u001b[39mhandover_info_log.csv\u001b[39m\u001b[39m'\u001b[39m), index\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jackbedford/Desktop/MOXA/Code/wmnl-handoff-research/analysis/2023-11-21-label_ho.ipynb#X22sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m     \u001b[39mif\u001b[39;00m df_ho\u001b[39m.\u001b[39mempty:\n",
      "\u001b[1;32m/Users/jackbedford/Desktop/MOXA/Code/wmnl-handoff-research/analysis/2023-11-21-label_ho.ipynb Cell 17\u001b[0m line \u001b[0;36m4\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/jackbedford/Desktop/MOXA/Code/wmnl-handoff-research/analysis/2023-11-21-label_ho.ipynb#X22sZmlsZQ%3D%3D?line=384'>385</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m m_src, m_tgt, s_src, s_tgt\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/jackbedford/Desktop/MOXA/Code/wmnl-handoff-research/analysis/2023-11-21-label_ho.ipynb#X22sZmlsZQ%3D%3D?line=386'>387</a>\u001b[0m key_mapping \u001b[39m=\u001b[39m {\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/jackbedford/Desktop/MOXA/Code/wmnl-handoff-research/analysis/2023-11-21-label_ho.ipynb#X22sZmlsZQ%3D%3D?line=387'>388</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mConn_Rel\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mCXNR\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/jackbedford/Desktop/MOXA/Code/wmnl-handoff-research/analysis/2023-11-21-label_ho.ipynb#X22sZmlsZQ%3D%3D?line=388'>389</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mConn_Req\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mCXNS\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/jackbedford/Desktop/MOXA/Code/wmnl-handoff-research/analysis/2023-11-21-label_ho.ipynb#X22sZmlsZQ%3D%3D?line=398'>399</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mAdd_SCell\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mSCLA\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/jackbedford/Desktop/MOXA/Code/wmnl-handoff-research/analysis/2023-11-21-label_ho.ipynb#X22sZmlsZQ%3D%3D?line=399'>400</a>\u001b[0m }\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/jackbedford/Desktop/MOXA/Code/wmnl-handoff-research/analysis/2023-11-21-label_ho.ipynb#X22sZmlsZQ%3D%3D?line=401'>402</a>\u001b[0m D \u001b[39m=\u001b[39m parse_mi_ho(df, tz)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/jackbedford/Desktop/MOXA/Code/wmnl-handoff-research/analysis/2023-11-21-label_ho.ipynb#X22sZmlsZQ%3D%3D?line=403'>404</a>\u001b[0m \u001b[39m# rename as acronym\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/jackbedford/Desktop/MOXA/Code/wmnl-handoff-research/analysis/2023-11-21-label_ho.ipynb#X22sZmlsZQ%3D%3D?line=404'>405</a>\u001b[0m new_D \u001b[39m=\u001b[39m {key_mapping\u001b[39m.\u001b[39mget(key, key): value \u001b[39mfor\u001b[39;00m key, value \u001b[39min\u001b[39;00m D\u001b[39m.\u001b[39mitems()}\n",
      "\u001b[1;32m/Users/jackbedford/Desktop/MOXA/Code/wmnl-handoff-research/analysis/2023-11-21-label_ho.ipynb Cell 17\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/jackbedford/Desktop/MOXA/Code/wmnl-handoff-research/analysis/2023-11-21-label_ho.ipynb#X22sZmlsZQ%3D%3D?line=169'>170</a>\u001b[0m orig_serv \u001b[39m=\u001b[39m (nr_pci, nr_arfcn) \u001b[39mif\u001b[39;00m nr_pci \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mO\u001b[39m\u001b[39m'\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mO\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/jackbedford/Desktop/MOXA/Code/wmnl-handoff-research/analysis/2023-11-21-label_ho.ipynb#X22sZmlsZQ%3D%3D?line=170'>171</a>\u001b[0m nr_pci \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(df[\u001b[39m'\u001b[39m\u001b[39mnr_physCellId\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39miloc[i])\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/jackbedford/Desktop/MOXA/Code/wmnl-handoff-research/analysis/2023-11-21-label_ho.ipynb#X22sZmlsZQ%3D%3D?line=171'>172</a>\u001b[0m nr_arfcn \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(df[\u001b[39m'\u001b[39;49m\u001b[39mabsoluteFrequencySSB\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39miloc[i])\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/jackbedford/Desktop/MOXA/Code/wmnl-handoff-research/analysis/2023-11-21-label_ho.ipynb#X22sZmlsZQ%3D%3D?line=172'>173</a>\u001b[0m trans \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m(\u001b[39m\u001b[39m{\u001b[39;00mserv_cell\u001b[39m}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m{\u001b[39;00mserv_freq\u001b[39m}\u001b[39;00m\u001b[39m) | \u001b[39m\u001b[39m{\u001b[39;00morig_serv\u001b[39m}\u001b[39;00m\u001b[39m -> (\u001b[39m\u001b[39m{\u001b[39;00mnr_pci\u001b[39m}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m{\u001b[39;00mnr_arfcn\u001b[39m}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/jackbedford/Desktop/MOXA/Code/wmnl-handoff-research/analysis/2023-11-21-label_ho.ipynb#X22sZmlsZQ%3D%3D?line=173'>174</a>\u001b[0m D[\u001b[39m'\u001b[39m\u001b[39mSN_setup\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mappend(HO(start\u001b[39m=\u001b[39mt, end\u001b[39m=\u001b[39mend, others\u001b[39m=\u001b[39mothers, trans\u001b[39m=\u001b[39mtrans))\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/moxa/lib/python3.8/site-packages/pandas/core/frame.py:3807\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3805\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   3806\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3807\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[1;32m   3808\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3809\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/moxa/lib/python3.8/site-packages/pandas/core/indexes/base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> 3804\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3805\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3806\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3807\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3808\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3809\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'absoluteFrequencySSB'"
     ]
    }
   ],
   "source": [
    "mcgf = [f'MCGF_{suffix}' for suffix in ['reconfigurationFailure (0)', 'handoverFailure (1)', 'otherFailure (2)']]\n",
    "nasr = [f'NASR_{suffix}' for suffix in ['reconfigurationFailure (0)', 'handoverFailure (1)', 'otherFailure (2)']]\n",
    "scgf = [f'SCGF_{suffix}' for suffix in ['t310-Expiry (0)', 'randomAccessProblem (1)', 'rlc-MaxNumRetx (2)', 'synchReconfigFailureSCG (3)', 'scg-ReconfigFailure (4)', 'srb3-IntegrityFailure (5)', 'other-r16 (6)']]\n",
    "\n",
    "evt_types = [\n",
    "    'LTEH', 'ENBH', 'MCGH', 'MNBH', 'SCGM', 'SCGA', 'SCGR-I', 'SCGC-I', 'SCGR-II', 'SCGC-II',\n",
    "    'MCGF', *mcgf,\n",
    "    'NASR', *nasr,\n",
    "    'SCGF', *scgf,\n",
    "]\n",
    "\n",
    "# record all traces' info in each type list\n",
    "# D = {tag: [] for tag in evt_types}\n",
    "# D['stable_mets'] = []\n",
    "# D['duration'] = []\n",
    "\n",
    "Metrics = namedtuple('Metrics', ['dl_pkt', 'dl_lost', 'dl_excl', 'ul_pkt', 'ul_lost', 'ul_excl'])\n",
    "Stats = namedtuple('Stats', ['count', 'duration', 'metrics'])\n",
    "Stage = namedtuple('Stage', ['before', 'during', 'after'])\n",
    "\n",
    "# for i, rrc_file, dl_file, ul_file in filepaths[940:]:\n",
    "for i, rrc_file, dl_file, ul_file in filepaths:\n",
    "    ########### in for loop (iterating exprs) ##### start\n",
    "    print(i, (rrc_file, dl_file, ul_file))\n",
    "    df_ho, _ = mi_parse_handover(pd.read_csv(rrc_file), radical=True, endfill=True)\n",
    "    df_ho.to_csv(os.path.join(os.path.dirname(rrc_file), 'handover_info_log.csv'), index=False)\n",
    "    \n",
    "    if df_ho.empty:\n",
    "        continue\n",
    "    \n",
    "    df_dl = set_data(pd.read_csv(dl_file))\n",
    "    df_ul = set_data(pd.read_csv(ul_file))\n",
    "    E, df_dl, df_ul = handover_classify_labelling(df_ho, df_dl, df_ul)\n",
    "    \n",
    "    # store handover labelling to avoid parsing again and again\n",
    "    df_dl.to_pickle(os.path.join(os.path.dirname(dl_file), 'udp_dnlk_loss_latency_ho.pkl'))\n",
    "    df_ul.to_pickle(os.path.join(os.path.dirname(ul_file), 'udp_uplk_loss_latency_ho.pkl'))\n",
    "    with open(os.path.join(os.path.dirname(rrc_file), 'single_radio_ho_stats.pkl'), 'wb') as f:\n",
    "        pickle.dump(metrics_duration_into_dict(E), f)\n",
    "\n",
    "    # for tag in evt_types:\n",
    "    #     # print(tag)\n",
    "    #     infos = []\n",
    "    #     for i, stage in enumerate(['before', 'during', 'after']):\n",
    "    #         # count\n",
    "    #         count = len(E[stage][tag])\n",
    "    #         # duration\n",
    "    #         duration = 0\n",
    "    #         intv_list = [item[0] for item in E[stage][tag]]\n",
    "    #         for intv in intv_list:\n",
    "    #             if intv.empty:\n",
    "    #                 continue\n",
    "    #             duration += (intv.upper - intv.lower).total_seconds()\n",
    "    #         # metrics\n",
    "    #         mets_list = [item[1] for item in E[stage][tag]]\n",
    "    #         metrics = Metrics(sum([item.dl_pkt for item in mets_list]), sum([item.dl_lost for item in mets_list]), sum([item.dl_excl for item in mets_list]), sum([item.ul_pkt for item in mets_list]), sum([item.ul_lost for item in mets_list]), sum([item.ul_excl for item in mets_list]))\n",
    "            \n",
    "    #         # print(stage, count, duration, metrics)\n",
    "    #         infos.append(Stats(count, duration, metrics))\n",
    "    #     D[tag].append(Stage(*infos))\n",
    "        \n",
    "    # D['stable_mets'].append(E['overview']['stable_intv'][1])\n",
    "    # D['duration'].append(E['overview']['duration'])\n",
    "    ########## in for loop (iterating exprs) ##### end\n",
    "    # break\n",
    "\n",
    "# pprint(D, sort_dicts=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "moxa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
