{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import sys\n",
    "import os\n",
    "from pprint import pprint\n",
    "import argparse\n",
    "from pytictoc import TicToc\n",
    "from itertools import chain\n",
    "import shutil\n",
    "import re\n",
    "\n",
    "def makedir(dirpath, mode=0):  # mode=1: show message, mode=0: hide message\n",
    "    if os.path.isdir(dirpath):\n",
    "        if mode:\n",
    "            print(\"mkdir: cannot create directory '{}': directory has already existed.\".format(dirpath))\n",
    "        return\n",
    "    ### recursively make directory\n",
    "    _temp = []\n",
    "    while not os.path.isdir(dirpath):\n",
    "        _temp.append(dirpath)\n",
    "        dirpath = os.path.dirname(dirpath)\n",
    "    while _temp:\n",
    "        dirpath = _temp.pop()\n",
    "        print(\"mkdir\", dirpath)\n",
    "        os.mkdir(dirpath)\n",
    "\n",
    "def xml_to_csv_nr_ml1(fin, fout):\n",
    "    f = open(fin, encoding=\"utf-8\")\n",
    "    f2 = open(fout, 'w') # _nr_ml1.csv\n",
    "    # print(\"nr_ml1 >>>>>\")\n",
    "    # Writing the column names...\n",
    "    # -------------------------------------------------/\n",
    "    # columns = [\"time\", \"type_id\",\n",
    "    columns = [\"Timestamp\", \"type_id\",\n",
    "        \"Raster ARFCN\",\n",
    "        \"Num Cells\",\n",
    "        \"Serving Cell Index\",\n",
    "        \"Serving Cell PCI\",\n",
    "        ]\n",
    "    f2.write(\",\".join(columns)+'\\n')\n",
    "\n",
    "    l = f.readline()\n",
    "\n",
    "    max_length = 0\n",
    "    while l:\n",
    "        if r\"<dm_log_packet>\" in l:\n",
    "            soup = BeautifulSoup(l, 'html.parser')\n",
    "            timestamp = soup.find(key=\"timestamp\").get_text()\n",
    "            type_id = soup.find(key=\"type_id\").get_text()\n",
    "\n",
    "            if type_id == '5G_NR_ML1_Searcher_Measurement_Database_Update_Ext':\n",
    "                arfcn = soup.find(key=\"Raster ARFCN\").get_text()\n",
    "                num_cells = soup.find(key=\"Num Cells\").get_text()\n",
    "                serving_cell_idex = soup.find(key=\"Serving Cell Index\").get_text()\n",
    "                serving_cell_pci = soup.find(key=\"Serving Cell PCI\").get_text()\n",
    "                pcis = [pci.get_text() for pci in soup.findAll(key=\"PCI\")]\n",
    "                rsrps = [rsrp.get_text() for rsrp in soup.findAll(key=\"Cell Quality Rsrp\")]\n",
    "                rsrqs = [rsrq.get_text() for rsrq in soup.findAll(key=\"Cell Quality Rsrq\")]\n",
    "\n",
    "                A = []\n",
    "                for i in range(int(num_cells)):    \n",
    "                    A.append(pcis[i])\n",
    "                    A.append(rsrps[i])\n",
    "                    A.append(rsrqs[i])\n",
    "\n",
    "                x = len([timestamp, type_id, arfcn, num_cells, serving_cell_idex, serving_cell_pci] + A)\n",
    "                max_length = x if x > max_length else max_length\n",
    "                f2.write(\",\".join([timestamp, type_id, arfcn, num_cells, serving_cell_idex, serving_cell_pci] + A)+'\\n')\n",
    "            \n",
    "            else: # 只處理nr_ml1資料過濾其他type\n",
    "                while l and r\"</dm_log_packet>\" not in l:\n",
    "                    l = f.readline()\n",
    "\n",
    "            l = f.readline()\n",
    "            \n",
    "        else:\n",
    "            print(l,\"Error!\")\n",
    "            delete = True\n",
    "            break \n",
    "            \n",
    "    f2.close()\n",
    "    f.close()\n",
    "\n",
    "    # csv Header process\n",
    "    with open(fout, 'r') as csvinput:\n",
    "        new_f = fout[:-4]+\"_new.csv\"\n",
    "        l = csvinput.readline()\n",
    "        x = len(l.split(','))\n",
    "        X = []\n",
    "        for i in range(int((max_length-x)/3)):\n",
    "            X += [f\"PCI{i}\",f\"RSRP{i}\",f\"RSRQ{i}\"]\n",
    "        X = columns+X\n",
    "        with open(new_f, 'w') as csvoutput:\n",
    "            csvoutput.write(\",\".join(X)+'\\n')\n",
    "            l = csvinput.readline()\n",
    "            while l:\n",
    "                csvoutput.write(l)\n",
    "                l = csvinput.readline()\n",
    "    os.system(f\"rm {fout}\") # Remove\n",
    "    os.system(f\"mv {new_f} {fout}\") # Rename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir ./temp3\n"
     ]
    }
   ],
   "source": [
    "path = \"./temp\"\n",
    "makedir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database = \"/home/wmnlab/D/database/\"\n",
    "# database = \"/Users/jackbedford/Desktop/MOXA/Code/data/\"\n",
    "dates = [\n",
    "    \"2023-05-04\",\n",
    "]\n",
    "exps = {  # experiment_name: (number_of_experiment_rounds, list_of_experiment_round)\n",
    "            # If the list is None, it will not list as directories.\n",
    "            # If the list is empty, it will list all directories in the current directory by default.\n",
    "            # If the number of experiment times != the length of existing directories of list, it would trigger warning and skip the directory.\n",
    "    \"_Bandlock_8_Schemes_Phone\": (6, [\"#{:02d}\".format(i+1) for i in range(6)]),\n",
    "}\n",
    "_devices = [\n",
    "    [\"sm00\", \"sm01\", \"sm02\", \"sm03\", \"sm04\", \"sm05\", \"sm06\", \"sm07\",],\n",
    "]\n",
    "_schemes = [\n",
    "    [\"All\", \"B3\", \"B7\", \"B8\", \"B3B7\", \"B3B8\", \"B7B8\", \"LTE\",],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fgetter():\n",
    "    files_collection = []\n",
    "    tags = \"diag_log\"\n",
    "    for filename in filenames:\n",
    "        if filename.startswith(tags) and filename.endswith(\".txt\"):\n",
    "            files_collection.append(filename)\n",
    "    return files_collection\n",
    "\n",
    "def main():\n",
    "    files_collection = fgetter()\n",
    "    if len(files_collection) == 0:\n",
    "        print(\"No candidate file.\")\n",
    "    for filename in files_collection:\n",
    "        fin = os.path.join(source_dir, filename)\n",
    "        # fout1 = os.path.join(target_dir, \"{}_rrc.csv\".format(filename[:-4]))\n",
    "        # fout2 = os.path.join(target_dir, \"{}_ml1.csv\".format(filename[:-4]))\n",
    "        fout3 = os.path.join(target_dir, \"{}_nr_ml1.csv\".format(filename[:-4]))\n",
    "        # print(\">>>>> convert from '{}' into '{}'...\".format(fin, fout1))\n",
    "        # xml_to_csv_rrc(fin, fout1)\n",
    "        # savemove(os.path.join(source_dir, \"{}_rrc.csv\".format(filename[:-4])), target_dir, \"{}_rrc.csv\".format(filename[:-4]))\n",
    "        # print(\">>>>> convert from '{}' into '{}'...\".format(fin, fout2))\n",
    "        # xml_to_csv_ml1(fin, fout2)\n",
    "        # savemove(os.path.join(source_dir, \"{}_ml1.csv\".format(filename[:-4])), target_dir, \"{}_ml1.csv\".format(filename[:-4]))\n",
    "        print(\">>>>> convert from '{}' into '{}'...\".format(fin, fout3))\n",
    "        xml_to_csv_nr_ml1(fin, fout3)\n",
    "        # savemove(os.path.join(source_dir, \"{}_nr_ml1.csv\".format(filename[:-4])), target_dir, \"{}_nr_ml1.csv\".format(filename[:-4]))\n",
    "    print()\n",
    "\n",
    "# ******************************* Check Files *********************************\n",
    "for date in dates:\n",
    "    for (expr, (times, traces)), devices in zip(exps.items(), _devices):\n",
    "        print(os.path.join(database, date, expr))\n",
    "        for dev in devices:\n",
    "            if not os.path.isdir(os.path.join(database, date, expr, dev)):\n",
    "                print(\"|___ {} does not exist.\".format(os.path.join(database, date, expr, dev)))\n",
    "                continue\n",
    "            \n",
    "            print(\"|___\", os.path.join(database, date, expr, dev))\n",
    "            if traces == None:\n",
    "                # print(os.path.join(database, date, expr, dev))\n",
    "                continue\n",
    "            elif len(traces) == 0:\n",
    "                traces = sorted(os.listdir(os.path.join(database, date, expr, dev)))\n",
    "            \n",
    "            print(\"|    \", times)\n",
    "            traces = [trace for trace in traces if os.path.isdir(os.path.join(database, date, expr, dev, trace))]\n",
    "            if len(traces) != times:\n",
    "                print(\"***************************************************************************************\")\n",
    "                print(\"Warning: the number of traces does not match the specified number of experiment times.\")\n",
    "                print(\"***************************************************************************************\")\n",
    "            for trace in traces:\n",
    "                print(\"|    |___\", os.path.join(database, date, expr, dev, trace))\n",
    "        print()\n",
    "# *****************************************************************************\n",
    "\n",
    "# ******************************** Processing *********************************\n",
    "t = TicToc()  # create instance of class\n",
    "t.tic()       # Start timer\n",
    "err_handles = []\n",
    "for date in dates:\n",
    "    for (expr, (times, traces)), devices in zip(exps.items(), _devices):\n",
    "        for dev in devices:\n",
    "            if not os.path.isdir(os.path.join(database, date, expr, dev)):\n",
    "                print(\"{} does not exist.\\n\".format(os.path.join(database, date, expr, dev)))\n",
    "                continue\n",
    "\n",
    "            if traces == None:\n",
    "                print(\"------------------------------------------\")\n",
    "                print(date, expr, dev)\n",
    "                print(\"------------------------------------------\")\n",
    "                source_dir = os.path.join(database, date, expr, dev)\n",
    "                target_dir = os.path.join(database, date, expr, dev)\n",
    "                makedir(target_dir)\n",
    "                filenames = os.listdir(source_dir)\n",
    "                main()\n",
    "                continue\n",
    "            elif len(traces) == 0:\n",
    "                traces = sorted(os.listdir(os.path.join(database, date, expr, dev)))\n",
    "            \n",
    "            traces = [trace for trace in traces if os.path.isdir(os.path.join(database, date, expr, dev, trace))]\n",
    "            for trace in traces:\n",
    "                print(\"------------------------------------------\")\n",
    "                print(date, expr, dev, trace)\n",
    "                print(\"------------------------------------------\")\n",
    "                source_dir = os.path.join(database, date, expr, dev, trace, \"middle\")\n",
    "                # target_dir = os.path.join(database, date, expr, dev, trace, \"data\")\n",
    "                target_dir = \"./temp\"\n",
    "                makedir(target_dir)\n",
    "                filenames = os.listdir(source_dir)\n",
    "                main()\n",
    "t.toc()  # Time elapsed since t.tic()\n",
    "# *****************************************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "moxa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
